{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "359950d8",
   "metadata": {},
   "source": [
    "# Data Processing Pipeline Demo: From Raw to Analysis-Ready Data\n",
    "\n",
    "This notebook demonstrates the complete data processing pipeline for Lightcast job market data, showcasing how our custom classes transform raw CSV data into clean, analysis-ready datasets.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "**Raw Data** â†’ **Data Loading** â†’ **Cleaning & Standardization** â†’ **Feature Engineering** â†’ **Quality Assessment** â†’ **Export & Persistence**\n",
    "\n",
    "## Key Components Demonstrated\n",
    "\n",
    "- **SparkJobAnalyzer**: Scalable data loading and analysis engine\n",
    "- **JobMarketDataProcessor**: Comprehensive data cleaning and feature engineering\n",
    "- **SalaryVisualizer**: Visualization and analysis utilities\n",
    "- **Multi-format Export**: Parquet, CSV, JSON schema generation\n",
    "- **Performance Monitoring**: Processing metrics and benchmarks\n",
    "\n",
    "## Target Audience\n",
    "\n",
    "- Data engineers implementing similar pipelines\n",
    "- Developers wanting to understand our data processing approach\n",
    "- Analysts who need to understand data transformations\n",
    "- Anyone interested in production-quality data processing with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c59826",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup and Dependencies\n",
    "\n",
    "First, we'll set up our environment and import the necessary libraries including our custom classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b18355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Data Processing Pipeline Demo\n",
      "==================================================\n",
      "Demo started at: 2025-09-29 21:37:48\n",
      "Python version: 3.12.9\n",
      "\n",
      "Custom Classes Imported Successfully:\n",
      "  - SparkJobAnalyzer: Data loading and analysis\n",
      "  - JobMarketDataProcessor: Data cleaning and processing\n",
      "  - SalaryVisualizer: Visualization utilities\n",
      "  - clean_and_process_data_optimized: Advanced processing pipeline\n",
      "\n",
      "Standard Libraries Imported:\n",
      "  - pandas, numpy: Data manipulation\n",
      "  - pyspark: Distributed computing\n",
      "\n",
      "Environment Setup Complete!\n",
      "Ready to demonstrate the data processing pipeline.\n",
      "\n",
      "Custom Classes Imported Successfully:\n",
      "  - SparkJobAnalyzer: Data loading and analysis\n",
      "  - JobMarketDataProcessor: Data cleaning and processing\n",
      "  - SalaryVisualizer: Visualization utilities\n",
      "  - clean_and_process_data_optimized: Advanced processing pipeline\n",
      "\n",
      "Standard Libraries Imported:\n",
      "  - pandas, numpy: Data manipulation\n",
      "  - pyspark: Distributed computing\n",
      "\n",
      "Environment Setup Complete!\n",
      "Ready to demonstrate the data processing pipeline.\n"
     ]
    }
   ],
   "source": [
    "# Environment Setup and Library Imports\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path for custom imports\n",
    "sys.path.append('../src')\n",
    "\n",
    "print(\"Setting up Data Processing Pipeline Demo\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Demo started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Import our custom classes\n",
    "try:\n",
    "    from data.spark_analyzer import SparkJobAnalyzer, create_raw_analyzer\n",
    "    from data.enhanced_processor import JobMarketDataProcessor\n",
    "    from data.full_dataset_processor import clean_and_process_data_optimized\n",
    "    from visualization.simple_plots import SalaryVisualizer\n",
    "    \n",
    "    print(\"\\nCustom Classes Imported Successfully:\")\n",
    "    print(\"  - SparkJobAnalyzer: Data loading and analysis\")\n",
    "    print(\"  - JobMarketDataProcessor: Data cleaning and processing\") \n",
    "    print(\"  - SalaryVisualizer: Visualization utilities\")\n",
    "    print(\"  - clean_and_process_data_optimized: Advanced processing pipeline\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Error importing custom classes: {e}\")\n",
    "    print(\"Please ensure you're running from the notebooks directory\")\n",
    "\n",
    "# Import standard data processing libraries\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import col, count, avg, min as spark_min, max as spark_max\n",
    "    \n",
    "    print(\"\\nStandard Libraries Imported:\")\n",
    "    print(\"  - pandas, numpy: Data manipulation\")\n",
    "    print(\"  - pyspark: Distributed computing\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Error importing standard libraries: {e}\")\n",
    "\n",
    "print(\"\\nEnvironment Setup Complete!\")\n",
    "print(\"Ready to demonstrate the data processing pipeline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e37ddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Data File Availability\n",
      "========================================\n",
      "raw_lightcast       : Available\n",
      "                      Size: 683.5 MB\n",
      "processed_parquet   : Missing\n",
      "sample_csv          : Missing\n",
      "\n",
      "Files found: 1/3\n",
      "\n",
      "All required files found - ready to proceed with demo!\n",
      "\n",
      "Configuring Spark Session for Demo\n",
      "-----------------------------------\n",
      "Spark Configuration:\n",
      "  spark.app.name: DataProcessingPipelineDemo\n",
      "  spark.sql.adaptive.enabled: true\n",
      "  spark.sql.adaptive.coalescePartitions.enabled: true\n",
      "  spark.driver.memory: 4g\n",
      "  spark.driver.maxResultSize: 2g\n",
      "\n",
      "Environment verification complete!\n"
     ]
    }
   ],
   "source": [
    "# Verify Data File Availability and Configure Spark\n",
    "print(\"Checking Data File Availability\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Define expected data sources\n",
    "data_sources = {\n",
    "    \"raw_lightcast\": \"../data/raw/lightcast_job_postings.csv\",\n",
    "    \"processed_parquet\": \"../data/processed/job_market_processed.parquet\",\n",
    "    \"sample_csv\": \"../data/processed/clean_job_data.csv\"\n",
    "}\n",
    "\n",
    "# Check file availability\n",
    "available_files = {}\n",
    "for name, path in data_sources.items():\n",
    "    file_path = Path(path)\n",
    "    exists = file_path.exists()\n",
    "    status = \"Available\" if exists else \"Missing\"\n",
    "    \n",
    "    print(f\"{name:20}: {status}\")\n",
    "    \n",
    "    if exists:\n",
    "        if path.endswith('.csv'):\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"{'':20}  Size: {size_mb:.1f} MB\")\n",
    "        available_files[name] = path\n",
    "\n",
    "print(f\"\\nFiles found: {len(available_files)}/{len(data_sources)}\")\n",
    "\n",
    "# Verify we have the raw data file (minimum requirement)\n",
    "if \"raw_lightcast\" not in available_files:\n",
    "    print(\"\\nWARNING: Raw Lightcast data file not found!\")\n",
    "    print(\"Please ensure '../data/raw/lightcast_job_postings.csv' exists\")\n",
    "    print(\"This demo requires the raw data file to demonstrate the full pipeline.\")\n",
    "else:\n",
    "    print(\"\\nAll required files found - ready to proceed with demo!\")\n",
    "\n",
    "# Initialize Spark configuration for demo\n",
    "print(\"\\nConfiguring Spark Session for Demo\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "spark_config = {\n",
    "    \"spark.app.name\": \"DataProcessingPipelineDemo\",\n",
    "    \"spark.sql.adaptive.enabled\": \"true\",\n",
    "    \"spark.sql.adaptive.coalescePartitions.enabled\": \"true\",\n",
    "    \"spark.driver.memory\": \"4g\",\n",
    "    \"spark.driver.maxResultSize\": \"2g\"\n",
    "}\n",
    "\n",
    "print(\"Spark Configuration:\")\n",
    "for key, value in spark_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nEnvironment verification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225884b2",
   "metadata": {},
   "source": [
    "## Section 2: Raw Data Loading and Validation\n",
    "\n",
    "Now we'll demonstrate how to load raw Lightcast data using our SparkJobAnalyzer class and perform initial data quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6386371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE 1: RAW DATA LOADING\n",
      "==================================================\n",
      "Loading raw data using create_raw_analyzer()...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/09/29 21:37:50 WARN Utils: Your hostname, SamWin, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/09/29 21:37:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/09/29 21:37:50 WARN Utils: Your hostname, SamWin, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/09/29 21:37:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/29 21:37:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/09/29 21:37:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/09/29 21:37:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/09/29 21:37:51 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/09/29 21:37:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/09/29 21:37:51 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "INFO:data.spark_analyzer:SparkJobAnalyzer initialized with Spark 4.0.1\n",
      "INFO:data.spark_analyzer:ðŸ”„ FORCE RAW MODE: Bypassing processed data, loading from raw source\n",
      "WARNING:data.spark_analyzer:âš ï¸  DEVELOPER MODE: Loading raw data - processed optimizations bypassed\n",
      "INFO:data.spark_analyzer:Loading raw Lightcast data from: ../../data/raw/lightcast_job_postings.csv\n",
      "INFO:data.spark_analyzer:SparkJobAnalyzer initialized with Spark 4.0.1\n",
      "INFO:data.spark_analyzer:ðŸ”„ FORCE RAW MODE: Bypassing processed data, loading from raw source\n",
      "WARNING:data.spark_analyzer:âš ï¸  DEVELOPER MODE: Loading raw data - processed optimizations bypassed\n",
      "INFO:data.spark_analyzer:Loading raw Lightcast data from: ../../data/raw/lightcast_job_postings.csv\n",
      "INFO:data.spark_analyzer:âœ… Raw data loaded: 72,498 records, 131 columns         \n",
      "WARNING:data.spark_analyzer:âš ï¸  Note: Raw data may have different column names and require processing\n",
      "INFO:data.spark_analyzer:Validating raw dataset (flexible validation)\n",
      "INFO:data.spark_analyzer:âœ… Raw data loaded: 72,498 records, 131 columns         \n",
      "WARNING:data.spark_analyzer:âš ï¸  Note: Raw data may have different column names and require processing\n",
      "INFO:data.spark_analyzer:Validating raw dataset (flexible validation)\n",
      "INFO:data.spark_analyzer:âœ… Detected raw Lightcast schema                        \n",
      "INFO:data.spark_analyzer:ðŸ“Š Found salary columns: ['SALARY', 'SALARY_TO', 'SALARY_FROM']\n",
      "INFO:data.spark_analyzer:Raw dataset validation completed: 72,498 records\n",
      "INFO:data.spark_analyzer:âœ… Detected raw Lightcast schema                        \n",
      "INFO:data.spark_analyzer:ðŸ“Š Found salary columns: ['SALARY', 'SALARY_TO', 'SALARY_FROM']\n",
      "INFO:data.spark_analyzer:Raw dataset validation completed: 72,498 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded successfully in 13.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Overview:\n",
      "  Total Records: 72,498\n",
      "  Total Columns: 131\n",
      "  Loading Method: SparkJobAnalyzer.create_raw_analyzer()\n",
      "\n",
      "Column Type Distribution:\n",
      "  BooleanType(): 2 columns\n",
      "  IntegerType(): 38 columns\n",
      "  StringType(): 90 columns\n",
      "  TimestampType(): 1 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Demonstrate Raw Data Loading with SparkJobAnalyzer\n",
    "print(\"STAGE 1: RAW DATA LOADING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Method 1: Using create_raw_analyzer() - Forces fresh raw data load\n",
    "print(\"Loading raw data using create_raw_analyzer()...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # This function forces loading from raw CSV, bypassing any processed data\n",
    "    analyzer = create_raw_analyzer()\n",
    "    \n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"Raw data loaded successfully in {load_time:.2f} seconds\")\n",
    "    \n",
    "    # Get basic dataset metrics\n",
    "    raw_df = analyzer.get_df()\n",
    "    record_count = raw_df.count()\n",
    "    column_count = len(raw_df.columns)\n",
    "    \n",
    "    print(f\"\\nDataset Overview:\")\n",
    "    print(f\"  Total Records: {record_count:,}\")\n",
    "    print(f\"  Total Columns: {column_count}\")\n",
    "    print(f\"  Loading Method: SparkJobAnalyzer.create_raw_analyzer()\")\n",
    "    \n",
    "    # Show data types summary\n",
    "    print(f\"\\nColumn Type Distribution:\")\n",
    "    schema_summary = {}\n",
    "    for field in raw_df.schema.fields:\n",
    "        field_type = str(field.dataType)\n",
    "        schema_summary[field_type] = schema_summary.get(field_type, 0) + 1\n",
    "    \n",
    "    for dtype, count in sorted(schema_summary.items()):\n",
    "        print(f\"  {dtype}: {count} columns\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading raw data: {e}\")\n",
    "    analyzer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87f3cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STAGE 2: INITIAL DATA QUALITY ASSESSMENT\n",
      "==================================================\n",
      "Sample Data (First 3 records, key columns):\n",
      "+------------------+--------+--------------------+\n",
      "|             TITLE| COMPANY|            LOCATION|\n",
      "+------------------+--------+--------------------+\n",
      "|ET29C073C03D1F86B4|  894731|{\\n  \"lat\": 33.20...|\n",
      "|ET21DDA63780A7DC09|  133098|{\\n  \"lat\": 44.31...|\n",
      "|ET3037E0C947A02404|39063746|{\\n  \"lat\": 32.77...|\n",
      "+------------------+--------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Column Organization (131 total):\n",
      "  Identity: 1 columns\n",
      "    ID\n",
      "  Basic Info: 8 columns\n",
      "  Location: 5 columns\n",
      "    LOCATION, CITY, CITY_NAME, STATE, STATE_NAME\n",
      "  Salary: 3 columns\n",
      "    SALARY, SALARY_TO, SALARY_FROM\n",
      "  Employment: 6 columns\n",
      "  Remote/AI: 22 columns\n",
      "  Temporal: 3 columns\n",
      "    LAST_UPDATED_DATE, LAST_UPDATED_TIMESTAMP, POSTED\n",
      "\n",
      "Null Value Analysis (Critical Columns):\n",
      "+------------------+--------+--------------------+\n",
      "|             TITLE| COMPANY|            LOCATION|\n",
      "+------------------+--------+--------------------+\n",
      "|ET29C073C03D1F86B4|  894731|{\\n  \"lat\": 33.20...|\n",
      "|ET21DDA63780A7DC09|  133098|{\\n  \"lat\": 44.31...|\n",
      "|ET3037E0C947A02404|39063746|{\\n  \"lat\": 32.77...|\n",
      "+------------------+--------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Column Organization (131 total):\n",
      "  Identity: 1 columns\n",
      "    ID\n",
      "  Basic Info: 8 columns\n",
      "  Location: 5 columns\n",
      "    LOCATION, CITY, CITY_NAME, STATE, STATE_NAME\n",
      "  Salary: 3 columns\n",
      "    SALARY, SALARY_TO, SALARY_FROM\n",
      "  Employment: 6 columns\n",
      "  Remote/AI: 22 columns\n",
      "  Temporal: 3 columns\n",
      "    LAST_UPDATED_DATE, LAST_UPDATED_TIMESTAMP, POSTED\n",
      "\n",
      "Null Value Analysis (Critical Columns):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TITLE: 44 nulls (0.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  COMPANY: 44 nulls (0.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LOCATION: 44 nulls (0.1%)\n",
      "\n",
      "Raw data loading and initial assessment complete!\n",
      "Data is ready for the cleaning and processing pipeline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Perform Initial Data Quality Assessment\n",
    "if analyzer is not None:\n",
    "    print(\"\\nSTAGE 2: INITIAL DATA QUALITY ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    raw_df = analyzer.job_data\n",
    "    \n",
    "    # 1. Display sample records with key columns\n",
    "    print(\"Sample Data (First 3 records, key columns):\")\n",
    "    key_columns = ['TITLE', 'COMPANY', 'LOCATION', 'SALARY_AVG_IMPUTED']\n",
    "    existing_key_cols = [col for col in key_columns if col in raw_df.columns]\n",
    "    \n",
    "    if existing_key_cols:\n",
    "        raw_df.select(existing_key_cols).show(3, truncate=True)\n",
    "    \n",
    "    # 2. Column categorization for better understanding\n",
    "    all_columns = raw_df.columns\n",
    "    print(f\"\\nColumn Organization ({len(all_columns)} total):\")\n",
    "    \n",
    "    column_categories = {\n",
    "        'Identity': [col for col in all_columns if any(x in col.upper() for x in ['ID', 'JOB_ID'])],\n",
    "        'Basic Info': [col for col in all_columns if any(x in col.upper() for x in ['TITLE', 'COMPANY', 'DESCRIPTION'])],\n",
    "        'Location': [col for col in all_columns if any(x in col.upper() for x in ['LOCATION', 'CITY', 'STATE', 'COUNTRY'])],\n",
    "        'Salary': [col for col in all_columns if 'SALARY' in col.upper()],\n",
    "        'Employment': [col for col in all_columns if any(x in col.upper() for x in ['EMPLOYMENT', 'EXPERIENCE', 'EDUCATION'])],\n",
    "        'Industry': [col for col in all_columns if 'INDUSTRY' in col.upper()],\n",
    "        'Remote/AI': [col for col in all_columns if any(x in col.upper() for x in ['REMOTE', 'AI'])],\n",
    "        'Temporal': [col for col in all_columns if any(x in col.upper() for x in ['DATE', 'TIME', 'POSTED'])],\n",
    "    }\n",
    "    \n",
    "    for category, cols in column_categories.items():\n",
    "        if cols:\n",
    "            print(f\"  {category}: {len(cols)} columns\")\n",
    "            if len(cols) <= 5:  # Show column names if not too many\n",
    "                print(f\"    {', '.join(cols)}\")\n",
    "    \n",
    "    # 3. Quick null analysis for critical columns\n",
    "    print(f\"\\nNull Value Analysis (Critical Columns):\")\n",
    "    critical_columns = ['TITLE', 'COMPANY', 'LOCATION', 'SALARY_AVG_IMPUTED']\n",
    "    existing_critical = [col for col in critical_columns if col in raw_df.columns]\n",
    "    \n",
    "    for col in existing_critical:\n",
    "        null_count = raw_df.filter(raw_df[col].isNull()).count()\n",
    "        null_pct = (null_count / record_count) * 100 if record_count > 0 else 0\n",
    "        print(f\"  {col}: {null_count:,} nulls ({null_pct:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nRaw data loading and initial assessment complete!\")\n",
    "    print(\"Data is ready for the cleaning and processing pipeline.\")\n",
    "else:\n",
    "    print(\"Cannot proceed with quality assessment - raw data not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c69dc0",
   "metadata": {},
   "source": [
    "## Section 3: Data Cleaning Pipeline Demonstration\n",
    "\n",
    "This section showcases our JobMarketDataProcessor class and its comprehensive data cleaning capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e89fb580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.enhanced_processor:Initializing Enhanced Job Market Data Processor...\n",
      "INFO:data.enhanced_processor:Spark session initialized: 4.0.1\n",
      "INFO:data.enhanced_processor:Spark session initialized: 4.0.1\n",
      "INFO:data.enhanced_processor:Schema defined with 21 fields\n",
      "INFO:data.enhanced_processor:Schema defined with 21 fields\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE 3: DATA CLEANING PIPELINE\n",
      "==================================================\n",
      "Initializing JobMarketDataProcessor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor initialized with 72,498 raw records\n",
      "\n",
      "Applying Data Cleaning Pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.enhanced_processor:=== STARTING OPTIMIZED DATA CLEANING PIPELINE ===  \n",
      "INFO:data.enhanced_processor:=== STARTING OPTIMIZED DATA CLEANING PIPELINE ===  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling clean_and_process_data_optimized()...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.enhanced_processor:BEFORE CLEANING:                                   \n",
      "INFO:data.enhanced_processor:   â†’ Columns: 131\n",
      "INFO:data.enhanced_processor:   â†’ Records: 72,498\n",
      "INFO:data.enhanced_processor:Step 1: Dropping non-essential columns...\n",
      "INFO:data.enhanced_processor:   âœ… Dropped columns: ['LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'ACTIVE_SOURCES_INFO']\n",
      "INFO:data.enhanced_processor:Step 2: Handling REMOTE_TYPE_NAME nulls...\n",
      "INFO:data.enhanced_processor:BEFORE CLEANING:                                   \n",
      "INFO:data.enhanced_processor:   â†’ Columns: 131\n",
      "INFO:data.enhanced_processor:   â†’ Records: 72,498\n",
      "INFO:data.enhanced_processor:Step 1: Dropping non-essential columns...\n",
      "INFO:data.enhanced_processor:   âœ… Dropped columns: ['LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'ACTIVE_SOURCES_INFO']\n",
      "INFO:data.enhanced_processor:Step 2: Handling REMOTE_TYPE_NAME nulls...\n",
      "INFO:data.enhanced_processor:   â†’ REMOTE_TYPE_NAME nulls: 44 (0.1%)             \n",
      "INFO:data.enhanced_processor:   â†’ REMOTE_TYPE_NAME nulls: 44 (0.1%)             \n",
      "INFO:data.enhanced_processor:   âœ… Nulls replaced with 'Undefined'\n",
      "INFO:data.enhanced_processor:Step 3: Resolving CITY vs CITY_NAME duplication...\n",
      "INFO:data.enhanced_processor:   âœ… Nulls replaced with 'Undefined'\n",
      "INFO:data.enhanced_processor:Step 3: Resolving CITY vs CITY_NAME duplication...\n",
      "INFO:data.enhanced_processor:   â†’ Found city columns: ['CITY', 'CITY_NAME']\n",
      "INFO:data.enhanced_processor:   â†’ Found city columns: ['CITY', 'CITY_NAME']\n",
      "INFO:data.enhanced_processor:   âœ… Created unified CITY column from CITY and CITY_NAME\n",
      "INFO:data.enhanced_processor:Step 4: Removing duplicate county columns...\n",
      "INFO:data.enhanced_processor:   âœ… Created unified CITY column from CITY and CITY_NAME\n",
      "INFO:data.enhanced_processor:Step 4: Removing duplicate county columns...\n",
      "INFO:data.enhanced_processor:   âœ… Dropped COUNTY_INCOMING, renamed COUNTY_OUTGOING to COUNTY_ID\n",
      "INFO:data.enhanced_processor:   âœ… Dropped COUNTY_INCOMING, renamed COUNTY_OUTGOING to COUNTY_ID\n",
      "INFO:data.enhanced_processor:   âœ… Dropped COUNTY_NAME_INCOMING, renamed COUNTY_NAME_OUTGOING to COUNTY_NAME\n",
      "INFO:data.enhanced_processor:Step 5: Applying standard data cleaning pipeline...\n",
      "INFO:data.enhanced_processor:=== STARTING DATA CLEANING PIPELINE ===\n",
      "INFO:data.enhanced_processor:   âœ… Dropped COUNTY_NAME_INCOMING, renamed COUNTY_NAME_OUTGOING to COUNTY_NAME\n",
      "INFO:data.enhanced_processor:Step 5: Applying standard data cleaning pipeline...\n",
      "INFO:data.enhanced_processor:=== STARTING DATA CLEANING PIPELINE ===\n",
      "INFO:data.enhanced_processor:Step 1: Removing duplicate records...              \n",
      "INFO:data.enhanced_processor:Step 1: Removing duplicate records...              \n",
      "INFO:data.enhanced_processor:   Removed 3,300 duplicate records                 \n",
      "INFO:data.enhanced_processor:Step 2: Processing salary data...\n",
      "INFO:data.enhanced_processor:   Removed 3,300 duplicate records                 \n",
      "INFO:data.enhanced_processor:Step 2: Processing salary data...\n",
      "{\"ts\": \"2025-09-29 21:51:52.591\", \"level\": \"ERROR\", \"logger\": \"DataFrameQueryContextLogger\", \"msg\": \"[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `SALARY_MIN` cannot be resolved. Did you mean one of the following? [`SALARY_TO`, `SALARY`, `SALARY_FROM`, `MSA_NAME`, `BODY`]. SQLSTATE: 42703\", \"context\": {\"file\": \"line 452 in cell [22]\", \"line\": \"\", \"fragment\": \"col\", \"errorClass\": \"UNRESOLVED_COLUMN.WITH_SUGGESTION\"}, \"exception\": {\"class\": \"Py4JJavaError\", \"msg\": \"An error occurred while calling o608.withColumn.\\n: org.apache.spark.sql.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `SALARY_MIN` cannot be resolved. Did you mean one of the following? [`SALARY_TO`, `SALARY`, `SALARY_FROM`, `MSA_NAME`, `BODY`]. SQLSTATE: 42703;\\n'Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME#6107, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077, CASE WHEN 'rlike('SALARY_MIN, ^[0-9]+$) THEN cast('SALARY_MIN as double) ELSE null END AS SALARY_MIN_CLEAN#6612]\\n+- Deduplicate [TITLE#64, COMPANY#16, LOCATION#37, POSTED#4]\\n   +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47 AS COUNTY_NAME#6107, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\\n      +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\\n         +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46 AS COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\\n            +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\\n               +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY_UNIFIED#6076 AS CITY#6077]\\n                  +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY_UNIFIED#6076]\\n                     +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, coalesce(CASE WHEN (isnotnull(CITY_NAME#39) AND NOT (CITY_NAME#39 = )) THEN CITY_NAME#39 END, safe_base64_decode(CITY#38)#6075) AS CITY_UNIFIED#6076]\\n                        +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, CASE WHEN isnull(REMOTE_TYPE_NAME#33) THEN Undefined ELSE REMOTE_TYPE_NAME#33 END AS REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130]\\n                           +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#33, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130]\\n                              +- Relation [ID#0,LAST_UPDATED_DATE#1,LAST_UPDATED_TIMESTAMP#2,DUPLICATES#3,POSTED#4,EXPIRED#5,DURATION#6,SOURCE_TYPES#7,SOURCES#8,URL#9,ACTIVE_URLS#10,ACTIVE_SOURCES_INFO#11,TITLE_RAW#12,BODY#13,MODELED_EXPIRED#14,MODELED_DURATION#15,COMPANY#16,COMPANY_NAME#17,COMPANY_RAW#18,COMPANY_IS_STAFFING#19,EDUCATION_LEVELS#20,EDUCATION_LEVELS_NAME#21,MIN_EDULEVELS#22,MIN_EDULEVELS_NAME#23,MAX_EDULEVELS#24,MAX_EDULEVELS_NAME#25,EMPLOYMENT_TYPE#26,EMPLOYMENT_TYPE_NAME#27,MIN_YEARS_EXPERIENCE#28,MAX_YEARS_EXPERIENCE#29,IS_INTERNSHIP#30,SALARY#31,REMOTE_TYPE#32,REMOTE_TYPE_NAME#33,ORIGINAL_PAY_PERIOD#34,SALARY_TO#35,SALARY_FROM#36,LOCATION#37,CITY#38,CITY_NAME#39,COUNTY#40,COUNTY_NAME#41,MSA#42,MSA_NAME#43,STATE#44,STATE_NAME#45,COUNTY_OUTGOING#46,COUNTY_NAME_OUTGOING#47,COUNTY_INCOMING#48,COUNTY_NAME_INCOMING#49,MSA_OUTGOING#50,MSA_NAME_OUTGOING#51,MSA_INCOMING#52,MSA_NAME_INCOMING#53,NAICS2#54,NAICS2_NAME#55,NAICS3#56,NAICS3_NAME#57,NAICS4#58,NAICS4_NAME#59,NAICS5#60,NAICS5_NAME#61,NAICS6#62,NAICS6_NAME#63,TITLE#64,TITLE_NAME#65,TITLE_CLEAN#66,SKILLS#67,SKILLS_NAME#68,SPECIALIZED_SKILLS#69,SPECIALIZED_SKILLS_NAME#70,CERTIFICATIONS#71,CERTIFICATIONS_NAME#72,COMMON_SKILLS#73,COMMON_SKILLS_NAME#74,SOFTWARE_SKILLS#75,SOFTWARE_SKILLS_NAME#76,ONET#77,ONET_NAME#78,ONET_2019#79,ONET_2019_NAME#80,CIP6#81,CIP6_NAME#82,CIP4#83,CIP4_NAME#84,CIP2#85,CIP2_NAME#86,SOC_2021_2#87,SOC_2021_2_NAME#88,SOC_2021_3#89,SOC_2021_3_NAME#90,SOC_2021_4#91,SOC_2021_4_NAME#92,SOC_2021_5#93,SOC_2021_5_NAME#94,LOT_CAREER_AREA#95,LOT_CAREER_AREA_NAME#96,LOT_OCCUPATION#97,LOT_OCCUPATION_NAME#98,LOT_SPECIALIZED_OCCUPATION#99,LOT_SPECIALIZED_OCCUPATION_NAME#100,LOT_OCCUPATION_GROUP#101,LOT_OCCUPATION_GROUP_NAME#102,LOT_V6_SPECIALIZED_OCCUPATION#103,LOT_V6_SPECIALIZED_OCCUPATION_NAME#104,LOT_V6_OCCUPATION#105,LOT_V6_OCCUPATION_NAME#106,LOT_V6_OCCUPATION_GROUP#107,LOT_V6_OCCUPATION_GROUP_NAME#108,LOT_V6_CAREER_AREA#109,LOT_V6_CAREER_AREA_NAME#110,SOC_2#111,SOC_2_NAME#112,SOC_3#113,SOC_3_NAME#114,SOC_4#115,SOC_4_NAME#116,SOC_5#117,SOC_5_NAME#118,LIGHTCAST_SECTORS#119,LIGHTCAST_SECTORS_NAME#120,NAICS_2022_2#121,NAICS_2022_2_NAME#122,NAICS_2022_3#123,NAICS_2022_3_NAME#124,NAICS_2022_4#125,NAICS_2022_4_NAME#126,NAICS_2022_5#127,NAICS_2022_5_NAME#128,NAICS_2022_6#129,NAICS_2022_6_NAME#130] csv\\n\\n\\tat org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:401)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:169)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:404)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:402)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)\\n\\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)\\n\\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\tat scala.collection.immutable.List.foreach(List.scala:334)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6(CheckAnalysis.scala:402)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6$adapted(CheckAnalysis.scala:402)\\n\\tat scala.collection.immutable.List.foreach(List.scala:334)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:402)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:284)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:284)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:255)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:299)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:244)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:231)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:299)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:192)\\n\\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\\n\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:192)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\\n\\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\\n\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\\n\\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\\n\\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\\n\\tat scala.util.Try$.apply(Try.scala:217)\\n\\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\\n\\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)\\n\\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\\n\\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)\\n\\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)\\n\\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\\n\\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)\\n\\tat org.apache.spark.sql.classic.Dataset.withPlan(Dataset.scala:2263)\\n\\tat org.apache.spark.sql.classic.Dataset.withColumns(Dataset.scala:1283)\\n\\tat org.apache.spark.sql.classic.Dataset.withColumns(Dataset.scala:232)\\n\\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2187)\\n\\tat org.apache.spark.sql.classic.Dataset.withColumn(Dataset.scala:1819)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\\n\\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\\n\\tat py4j.Gateway.invoke(Gateway.java:282)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\\n\\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n\\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\\n\\t\\tat org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:401)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:169)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:404)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:402)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\t\\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)\\n\\t\\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)\\n\\t\\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\t\\tat scala.collection.immutable.List.foreach(List.scala:334)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\t\\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6(CheckAnalysis.scala:402)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6$adapted(CheckAnalysis.scala:402)\\n\\t\\tat scala.collection.immutable.List.foreach(List.scala:334)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:402)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:284)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:284)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:255)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:299)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:244)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:231)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:299)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:192)\\n\\t\\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\\n\\t\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:192)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\\n\\t\\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\\n\\t\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\\n\\t\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\\n\\t\\tat scala.util.Try$.apply(Try.scala:217)\\n\\t\\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\\n\\t\\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\\n\\t\\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\\n\\t\\t... 23 more\\n\", \"stacktrace\": [{\"class\": null, \"method\": \"deco\", \"file\": \"/home/samarthya/sourcebox/github.com/project-from-scratch/.venv/lib64/python3.12/site-packages/pyspark/errors/exceptions/captured.py\", \"line\": \"282\"}, {\"class\": null, \"method\": \"get_return_value\", \"file\": \"/home/samarthya/sourcebox/github.com/project-from-scratch/.venv/lib64/python3.12/site-packages/py4j/protocol.py\", \"line\": \"327\"}]}}\n",
      "{\"ts\": \"2025-09-29 21:51:52.591\", \"level\": \"ERROR\", \"logger\": \"DataFrameQueryContextLogger\", \"msg\": \"[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `SALARY_MIN` cannot be resolved. Did you mean one of the following? [`SALARY_TO`, `SALARY`, `SALARY_FROM`, `MSA_NAME`, `BODY`]. SQLSTATE: 42703\", \"context\": {\"file\": \"line 452 in cell [22]\", \"line\": \"\", \"fragment\": \"col\", \"errorClass\": \"UNRESOLVED_COLUMN.WITH_SUGGESTION\"}, \"exception\": {\"class\": \"Py4JJavaError\", \"msg\": \"An error occurred while calling o608.withColumn.\\n: org.apache.spark.sql.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `SALARY_MIN` cannot be resolved. Did you mean one of the following? [`SALARY_TO`, `SALARY`, `SALARY_FROM`, `MSA_NAME`, `BODY`]. SQLSTATE: 42703;\\n'Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME#6107, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077, CASE WHEN 'rlike('SALARY_MIN, ^[0-9]+$) THEN cast('SALARY_MIN as double) ELSE null END AS SALARY_MIN_CLEAN#6612]\\n+- Deduplicate [TITLE#64, COMPANY#16, LOCATION#37, POSTED#4]\\n   +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47 AS COUNTY_NAME#6107, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\\n      +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\\n         +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46 AS COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\\n            +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\\n               +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY_UNIFIED#6076 AS CITY#6077]\\n                  +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY_UNIFIED#6076]\\n                     +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, coalesce(CASE WHEN (isnotnull(CITY_NAME#39) AND NOT (CITY_NAME#39 = )) THEN CITY_NAME#39 END, safe_base64_decode(CITY#38)#6075) AS CITY_UNIFIED#6076]\\n                        +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, CASE WHEN isnull(REMOTE_TYPE_NAME#33) THEN Undefined ELSE REMOTE_TYPE_NAME#33 END AS REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130]\\n                           +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#33, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130]\\n                              +- Relation [ID#0,LAST_UPDATED_DATE#1,LAST_UPDATED_TIMESTAMP#2,DUPLICATES#3,POSTED#4,EXPIRED#5,DURATION#6,SOURCE_TYPES#7,SOURCES#8,URL#9,ACTIVE_URLS#10,ACTIVE_SOURCES_INFO#11,TITLE_RAW#12,BODY#13,MODELED_EXPIRED#14,MODELED_DURATION#15,COMPANY#16,COMPANY_NAME#17,COMPANY_RAW#18,COMPANY_IS_STAFFING#19,EDUCATION_LEVELS#20,EDUCATION_LEVELS_NAME#21,MIN_EDULEVELS#22,MIN_EDULEVELS_NAME#23,MAX_EDULEVELS#24,MAX_EDULEVELS_NAME#25,EMPLOYMENT_TYPE#26,EMPLOYMENT_TYPE_NAME#27,MIN_YEARS_EXPERIENCE#28,MAX_YEARS_EXPERIENCE#29,IS_INTERNSHIP#30,SALARY#31,REMOTE_TYPE#32,REMOTE_TYPE_NAME#33,ORIGINAL_PAY_PERIOD#34,SALARY_TO#35,SALARY_FROM#36,LOCATION#37,CITY#38,CITY_NAME#39,COUNTY#40,COUNTY_NAME#41,MSA#42,MSA_NAME#43,STATE#44,STATE_NAME#45,COUNTY_OUTGOING#46,COUNTY_NAME_OUTGOING#47,COUNTY_INCOMING#48,COUNTY_NAME_INCOMING#49,MSA_OUTGOING#50,MSA_NAME_OUTGOING#51,MSA_INCOMING#52,MSA_NAME_INCOMING#53,NAICS2#54,NAICS2_NAME#55,NAICS3#56,NAICS3_NAME#57,NAICS4#58,NAICS4_NAME#59,NAICS5#60,NAICS5_NAME#61,NAICS6#62,NAICS6_NAME#63,TITLE#64,TITLE_NAME#65,TITLE_CLEAN#66,SKILLS#67,SKILLS_NAME#68,SPECIALIZED_SKILLS#69,SPECIALIZED_SKILLS_NAME#70,CERTIFICATIONS#71,CERTIFICATIONS_NAME#72,COMMON_SKILLS#73,COMMON_SKILLS_NAME#74,SOFTWARE_SKILLS#75,SOFTWARE_SKILLS_NAME#76,ONET#77,ONET_NAME#78,ONET_2019#79,ONET_2019_NAME#80,CIP6#81,CIP6_NAME#82,CIP4#83,CIP4_NAME#84,CIP2#85,CIP2_NAME#86,SOC_2021_2#87,SOC_2021_2_NAME#88,SOC_2021_3#89,SOC_2021_3_NAME#90,SOC_2021_4#91,SOC_2021_4_NAME#92,SOC_2021_5#93,SOC_2021_5_NAME#94,LOT_CAREER_AREA#95,LOT_CAREER_AREA_NAME#96,LOT_OCCUPATION#97,LOT_OCCUPATION_NAME#98,LOT_SPECIALIZED_OCCUPATION#99,LOT_SPECIALIZED_OCCUPATION_NAME#100,LOT_OCCUPATION_GROUP#101,LOT_OCCUPATION_GROUP_NAME#102,LOT_V6_SPECIALIZED_OCCUPATION#103,LOT_V6_SPECIALIZED_OCCUPATION_NAME#104,LOT_V6_OCCUPATION#105,LOT_V6_OCCUPATION_NAME#106,LOT_V6_OCCUPATION_GROUP#107,LOT_V6_OCCUPATION_GROUP_NAME#108,LOT_V6_CAREER_AREA#109,LOT_V6_CAREER_AREA_NAME#110,SOC_2#111,SOC_2_NAME#112,SOC_3#113,SOC_3_NAME#114,SOC_4#115,SOC_4_NAME#116,SOC_5#117,SOC_5_NAME#118,LIGHTCAST_SECTORS#119,LIGHTCAST_SECTORS_NAME#120,NAICS_2022_2#121,NAICS_2022_2_NAME#122,NAICS_2022_3#123,NAICS_2022_3_NAME#124,NAICS_2022_4#125,NAICS_2022_4_NAME#126,NAICS_2022_5#127,NAICS_2022_5_NAME#128,NAICS_2022_6#129,NAICS_2022_6_NAME#130] csv\\n\\n\\tat org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:401)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:169)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:404)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:402)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)\\n\\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)\\n\\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\tat scala.collection.immutable.List.foreach(List.scala:334)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6(CheckAnalysis.scala:402)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6$adapted(CheckAnalysis.scala:402)\\n\\tat scala.collection.immutable.List.foreach(List.scala:334)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:402)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:284)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:284)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:255)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:299)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:244)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:231)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:299)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:192)\\n\\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\\n\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:192)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\\n\\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\\n\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\\n\\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\\n\\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\\n\\tat scala.util.Try$.apply(Try.scala:217)\\n\\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\\n\\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)\\n\\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\\n\\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)\\n\\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)\\n\\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\\n\\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)\\n\\tat org.apache.spark.sql.classic.Dataset.withPlan(Dataset.scala:2263)\\n\\tat org.apache.spark.sql.classic.Dataset.withColumns(Dataset.scala:1283)\\n\\tat org.apache.spark.sql.classic.Dataset.withColumns(Dataset.scala:232)\\n\\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2187)\\n\\tat org.apache.spark.sql.classic.Dataset.withColumn(Dataset.scala:1819)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\\n\\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\\n\\tat py4j.Gateway.invoke(Gateway.java:282)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\\n\\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n\\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\\n\\t\\tat org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:401)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:169)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:404)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:402)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\t\\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)\\n\\t\\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)\\n\\t\\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\t\\tat scala.collection.immutable.List.foreach(List.scala:334)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\t\\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6(CheckAnalysis.scala:402)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6$adapted(CheckAnalysis.scala:402)\\n\\t\\tat scala.collection.immutable.List.foreach(List.scala:334)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:402)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:284)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:284)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:255)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:299)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:244)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:231)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:299)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:192)\\n\\t\\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\\n\\t\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:192)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\\n\\t\\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\\n\\t\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\\n\\t\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\\n\\t\\tat scala.util.Try$.apply(Try.scala:217)\\n\\t\\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\\n\\t\\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\\n\\t\\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\\n\\t\\t... 23 more\\n\", \"stacktrace\": [{\"class\": null, \"method\": \"deco\", \"file\": \"/home/samarthya/sourcebox/github.com/project-from-scratch/.venv/lib64/python3.12/site-packages/pyspark/errors/exceptions/captured.py\", \"line\": \"282\"}, {\"class\": null, \"method\": \"get_return_value\", \"file\": \"/home/samarthya/sourcebox/github.com/project-from-scratch/.venv/lib64/python3.12/site-packages/py4j/protocol.py\", \"line\": \"327\"}]}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in cleaning pipeline: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `SALARY_MIN` cannot be resolved. Did you mean one of the following? [`SALARY_TO`, `SALARY`, `SALARY_FROM`, `MSA_NAME`, `BODY`]. SQLSTATE: 42703;\n",
      "'Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME#6107, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077, CASE WHEN 'rlike('SALARY_MIN, ^[0-9]+$) THEN cast('SALARY_MIN as double) ELSE null END AS SALARY_MIN_CLEAN#6612]\n",
      "+- Deduplicate [TITLE#64, COMPANY#16, LOCATION#37, POSTED#4]\n",
      "   +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47 AS COUNTY_NAME#6107, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\n",
      "      +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\n",
      "         +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46 AS COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\n",
      "            +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\n",
      "               +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY_UNIFIED#6076 AS CITY#6077]\n",
      "                  +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY_UNIFIED#6076]\n",
      "                     +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, coalesce(CASE WHEN (isnotnull(CITY_NAME#39) AND NOT (CITY_NAME#39 = )) THEN CITY_NAME#39 END, safe_base64_decode(CITY#38)#6075) AS CITY_UNIFIED#6076]\n",
      "                        +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, CASE WHEN isnull(REMOTE_TYPE_NAME#33) THEN Undefined ELSE REMOTE_TYPE_NAME#33 END AS REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130]\n",
      "                           +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#33, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130]\n",
      "                              +- Relation [ID#0,LAST_UPDATED_DATE#1,LAST_UPDATED_TIMESTAMP#2,DUPLICATES#3,POSTED#4,EXPIRED#5,DURATION#6,SOURCE_TYPES#7,SOURCES#8,URL#9,ACTIVE_URLS#10,ACTIVE_SOURCES_INFO#11,TITLE_RAW#12,BODY#13,MODELED_EXPIRED#14,MODELED_DURATION#15,COMPANY#16,COMPANY_NAME#17,COMPANY_RAW#18,COMPANY_IS_STAFFING#19,EDUCATION_LEVELS#20,EDUCATION_LEVELS_NAME#21,MIN_EDULEVELS#22,MIN_EDULEVELS_NAME#23,MAX_EDULEVELS#24,MAX_EDULEVELS_NAME#25,EMPLOYMENT_TYPE#26,EMPLOYMENT_TYPE_NAME#27,MIN_YEARS_EXPERIENCE#28,MAX_YEARS_EXPERIENCE#29,IS_INTERNSHIP#30,SALARY#31,REMOTE_TYPE#32,REMOTE_TYPE_NAME#33,ORIGINAL_PAY_PERIOD#34,SALARY_TO#35,SALARY_FROM#36,LOCATION#37,CITY#38,CITY_NAME#39,COUNTY#40,COUNTY_NAME#41,MSA#42,MSA_NAME#43,STATE#44,STATE_NAME#45,COUNTY_OUTGOING#46,COUNTY_NAME_OUTGOING#47,COUNTY_INCOMING#48,COUNTY_NAME_INCOMING#49,MSA_OUTGOING#50,MSA_NAME_OUTGOING#51,MSA_INCOMING#52,MSA_NAME_INCOMING#53,NAICS2#54,NAICS2_NAME#55,NAICS3#56,NAICS3_NAME#57,NAICS4#58,NAICS4_NAME#59,NAICS5#60,NAICS5_NAME#61,NAICS6#62,NAICS6_NAME#63,TITLE#64,TITLE_NAME#65,TITLE_CLEAN#66,SKILLS#67,SKILLS_NAME#68,SPECIALIZED_SKILLS#69,SPECIALIZED_SKILLS_NAME#70,CERTIFICATIONS#71,CERTIFICATIONS_NAME#72,COMMON_SKILLS#73,COMMON_SKILLS_NAME#74,SOFTWARE_SKILLS#75,SOFTWARE_SKILLS_NAME#76,ONET#77,ONET_NAME#78,ONET_2019#79,ONET_2019_NAME#80,CIP6#81,CIP6_NAME#82,CIP4#83,CIP4_NAME#84,CIP2#85,CIP2_NAME#86,SOC_2021_2#87,SOC_2021_2_NAME#88,SOC_2021_3#89,SOC_2021_3_NAME#90,SOC_2021_4#91,SOC_2021_4_NAME#92,SOC_2021_5#93,SOC_2021_5_NAME#94,LOT_CAREER_AREA#95,LOT_CAREER_AREA_NAME#96,LOT_OCCUPATION#97,LOT_OCCUPATION_NAME#98,LOT_SPECIALIZED_OCCUPATION#99,LOT_SPECIALIZED_OCCUPATION_NAME#100,LOT_OCCUPATION_GROUP#101,LOT_OCCUPATION_GROUP_NAME#102,LOT_V6_SPECIALIZED_OCCUPATION#103,LOT_V6_SPECIALIZED_OCCUPATION_NAME#104,LOT_V6_OCCUPATION#105,LOT_V6_OCCUPATION_NAME#106,LOT_V6_OCCUPATION_GROUP#107,LOT_V6_OCCUPATION_GROUP_NAME#108,LOT_V6_CAREER_AREA#109,LOT_V6_CAREER_AREA_NAME#110,SOC_2#111,SOC_2_NAME#112,SOC_3#113,SOC_3_NAME#114,SOC_4#115,SOC_4_NAME#116,SOC_5#117,SOC_5_NAME#118,LIGHTCAST_SECTORS#119,LIGHTCAST_SECTORS_NAME#120,NAICS_2022_2#121,NAICS_2022_2_NAME#122,NAICS_2022_3#123,NAICS_2022_3_NAME#124,NAICS_2022_4#125,NAICS_2022_4_NAME#126,NAICS_2022_5#127,NAICS_2022_5_NAME#128,NAICS_2022_6#129,NAICS_2022_6_NAME#130] csv\n",
      "\n",
      "Full traceback:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_4268/814263455.py\", line 26, in <module>\n",
      "    cleaned_df = processor.clean_and_process_data_optimized(processor.df_raw)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/samarthya/sourcebox/github.com/project-from-scratch/notebooks/../src/data/enhanced_processor.py\", line 788, in clean_and_process_data_optimized\n",
      "    df_cleaned = self.clean_and_process_data(df_cleaned)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/samarthya/sourcebox/github.com/project-from-scratch/notebooks/../src/data/enhanced_processor.py\", line 452, in clean_and_process_data\n",
      "    df_clean = df_clean.withColumn(\"SALARY_MIN_CLEAN\", when(col(\"SALARY_MIN\").rlike(\"^[0-9]+$\"), col(\"SALARY_MIN\").cast(\"double\")).otherwise(None)).withColumn(\"SALARY_MAX_CLEAN\", when(col(\"SALARY_MAX\").rlike(\"^[0-9]+$\"), col(\"SALARY_MAX\").cast(\"double\")).otherwise(None)).withColumn(\"SALARY_AVG\", (col(\"SALARY_MIN_CLEAN\") + col(\"SALARY_MAX_CLEAN\")) / 2)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/samarthya/sourcebox/github.com/project-from-scratch/.venv/lib64/python3.12/site-packages/pyspark/sql/classic/dataframe.py\", line 1623, in withColumn\n",
      "    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/samarthya/sourcebox/github.com/project-from-scratch/.venv/lib64/python3.12/site-packages/py4j/java_gateway.py\", line 1362, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/samarthya/sourcebox/github.com/project-from-scratch/.venv/lib64/python3.12/site-packages/pyspark/errors/exceptions/captured.py\", line 288, in deco\n",
      "    raise converted from None\n",
      "pyspark.errors.exceptions.captured.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `SALARY_MIN` cannot be resolved. Did you mean one of the following? [`SALARY_TO`, `SALARY`, `SALARY_FROM`, `MSA_NAME`, `BODY`]. SQLSTATE: 42703;\n",
      "'Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME#6107, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077, CASE WHEN 'rlike('SALARY_MIN, ^[0-9]+$) THEN cast('SALARY_MIN as double) ELSE null END AS SALARY_MIN_CLEAN#6612]\n",
      "+- Deduplicate [TITLE#64, COMPANY#16, LOCATION#37, POSTED#4]\n",
      "   +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47 AS COUNTY_NAME#6107, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\n",
      "      +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\n",
      "         +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46 AS COUNTY_ID#6092, COUNTY_NAME_OUTGOING#47, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\n",
      "            +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY#6077]\n",
      "               +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY_UNIFIED#6076 AS CITY#6077]\n",
      "                  +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, CITY_UNIFIED#6076]\n",
      "                     +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130, coalesce(CASE WHEN (isnotnull(CITY_NAME#39) AND NOT (CITY_NAME#39 = )) THEN CITY_NAME#39 END, safe_base64_decode(CITY#38)#6075) AS CITY_UNIFIED#6076]\n",
      "                        +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, CASE WHEN isnull(REMOTE_TYPE_NAME#33) THEN Undefined ELSE REMOTE_TYPE_NAME#33 END AS REMOTE_TYPE_NAME#6074, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130]\n",
      "                           +- Project [ID#0, DUPLICATES#3, POSTED#4, EXPIRED#5, DURATION#6, SOURCE_TYPES#7, SOURCES#8, URL#9, ACTIVE_URLS#10, TITLE_RAW#12, BODY#13, MODELED_EXPIRED#14, MODELED_DURATION#15, COMPANY#16, COMPANY_NAME#17, COMPANY_RAW#18, COMPANY_IS_STAFFING#19, EDUCATION_LEVELS#20, EDUCATION_LEVELS_NAME#21, MIN_EDULEVELS#22, MIN_EDULEVELS_NAME#23, MAX_EDULEVELS#24, MAX_EDULEVELS_NAME#25, EMPLOYMENT_TYPE#26, EMPLOYMENT_TYPE_NAME#27, MIN_YEARS_EXPERIENCE#28, MAX_YEARS_EXPERIENCE#29, IS_INTERNSHIP#30, SALARY#31, REMOTE_TYPE#32, REMOTE_TYPE_NAME#33, ORIGINAL_PAY_PERIOD#34, SALARY_TO#35, SALARY_FROM#36, LOCATION#37, CITY#38, CITY_NAME#39, COUNTY#40, COUNTY_NAME#41, MSA#42, MSA_NAME#43, STATE#44, STATE_NAME#45, COUNTY_OUTGOING#46, COUNTY_NAME_OUTGOING#47, COUNTY_INCOMING#48, COUNTY_NAME_INCOMING#49, MSA_OUTGOING#50, MSA_NAME_OUTGOING#51, MSA_INCOMING#52, MSA_NAME_INCOMING#53, NAICS2#54, NAICS2_NAME#55, NAICS3#56, NAICS3_NAME#57, NAICS4#58, NAICS4_NAME#59, NAICS5#60, NAICS5_NAME#61, NAICS6#62, NAICS6_NAME#63, TITLE#64, TITLE_NAME#65, TITLE_CLEAN#66, SKILLS#67, SKILLS_NAME#68, SPECIALIZED_SKILLS#69, SPECIALIZED_SKILLS_NAME#70, CERTIFICATIONS#71, CERTIFICATIONS_NAME#72, COMMON_SKILLS#73, COMMON_SKILLS_NAME#74, SOFTWARE_SKILLS#75, SOFTWARE_SKILLS_NAME#76, ONET#77, ONET_NAME#78, ONET_2019#79, ONET_2019_NAME#80, CIP6#81, CIP6_NAME#82, CIP4#83, CIP4_NAME#84, CIP2#85, CIP2_NAME#86, SOC_2021_2#87, SOC_2021_2_NAME#88, SOC_2021_3#89, SOC_2021_3_NAME#90, SOC_2021_4#91, SOC_2021_4_NAME#92, SOC_2021_5#93, SOC_2021_5_NAME#94, LOT_CAREER_AREA#95, LOT_CAREER_AREA_NAME#96, LOT_OCCUPATION#97, LOT_OCCUPATION_NAME#98, LOT_SPECIALIZED_OCCUPATION#99, LOT_SPECIALIZED_OCCUPATION_NAME#100, LOT_OCCUPATION_GROUP#101, LOT_OCCUPATION_GROUP_NAME#102, LOT_V6_SPECIALIZED_OCCUPATION#103, LOT_V6_SPECIALIZED_OCCUPATION_NAME#104, LOT_V6_OCCUPATION#105, LOT_V6_OCCUPATION_NAME#106, LOT_V6_OCCUPATION_GROUP#107, LOT_V6_OCCUPATION_GROUP_NAME#108, LOT_V6_CAREER_AREA#109, LOT_V6_CAREER_AREA_NAME#110, SOC_2#111, SOC_2_NAME#112, SOC_3#113, SOC_3_NAME#114, SOC_4#115, SOC_4_NAME#116, SOC_5#117, SOC_5_NAME#118, LIGHTCAST_SECTORS#119, LIGHTCAST_SECTORS_NAME#120, NAICS_2022_2#121, NAICS_2022_2_NAME#122, NAICS_2022_3#123, NAICS_2022_3_NAME#124, NAICS_2022_4#125, NAICS_2022_4_NAME#126, NAICS_2022_5#127, NAICS_2022_5_NAME#128, NAICS_2022_6#129, NAICS_2022_6_NAME#130]\n",
      "                              +- Relation [ID#0,LAST_UPDATED_DATE#1,LAST_UPDATED_TIMESTAMP#2,DUPLICATES#3,POSTED#4,EXPIRED#5,DURATION#6,SOURCE_TYPES#7,SOURCES#8,URL#9,ACTIVE_URLS#10,ACTIVE_SOURCES_INFO#11,TITLE_RAW#12,BODY#13,MODELED_EXPIRED#14,MODELED_DURATION#15,COMPANY#16,COMPANY_NAME#17,COMPANY_RAW#18,COMPANY_IS_STAFFING#19,EDUCATION_LEVELS#20,EDUCATION_LEVELS_NAME#21,MIN_EDULEVELS#22,MIN_EDULEVELS_NAME#23,MAX_EDULEVELS#24,MAX_EDULEVELS_NAME#25,EMPLOYMENT_TYPE#26,EMPLOYMENT_TYPE_NAME#27,MIN_YEARS_EXPERIENCE#28,MAX_YEARS_EXPERIENCE#29,IS_INTERNSHIP#30,SALARY#31,REMOTE_TYPE#32,REMOTE_TYPE_NAME#33,ORIGINAL_PAY_PERIOD#34,SALARY_TO#35,SALARY_FROM#36,LOCATION#37,CITY#38,CITY_NAME#39,COUNTY#40,COUNTY_NAME#41,MSA#42,MSA_NAME#43,STATE#44,STATE_NAME#45,COUNTY_OUTGOING#46,COUNTY_NAME_OUTGOING#47,COUNTY_INCOMING#48,COUNTY_NAME_INCOMING#49,MSA_OUTGOING#50,MSA_NAME_OUTGOING#51,MSA_INCOMING#52,MSA_NAME_INCOMING#53,NAICS2#54,NAICS2_NAME#55,NAICS3#56,NAICS3_NAME#57,NAICS4#58,NAICS4_NAME#59,NAICS5#60,NAICS5_NAME#61,NAICS6#62,NAICS6_NAME#63,TITLE#64,TITLE_NAME#65,TITLE_CLEAN#66,SKILLS#67,SKILLS_NAME#68,SPECIALIZED_SKILLS#69,SPECIALIZED_SKILLS_NAME#70,CERTIFICATIONS#71,CERTIFICATIONS_NAME#72,COMMON_SKILLS#73,COMMON_SKILLS_NAME#74,SOFTWARE_SKILLS#75,SOFTWARE_SKILLS_NAME#76,ONET#77,ONET_NAME#78,ONET_2019#79,ONET_2019_NAME#80,CIP6#81,CIP6_NAME#82,CIP4#83,CIP4_NAME#84,CIP2#85,CIP2_NAME#86,SOC_2021_2#87,SOC_2021_2_NAME#88,SOC_2021_3#89,SOC_2021_3_NAME#90,SOC_2021_4#91,SOC_2021_4_NAME#92,SOC_2021_5#93,SOC_2021_5_NAME#94,LOT_CAREER_AREA#95,LOT_CAREER_AREA_NAME#96,LOT_OCCUPATION#97,LOT_OCCUPATION_NAME#98,LOT_SPECIALIZED_OCCUPATION#99,LOT_SPECIALIZED_OCCUPATION_NAME#100,LOT_OCCUPATION_GROUP#101,LOT_OCCUPATION_GROUP_NAME#102,LOT_V6_SPECIALIZED_OCCUPATION#103,LOT_V6_SPECIALIZED_OCCUPATION_NAME#104,LOT_V6_OCCUPATION#105,LOT_V6_OCCUPATION_NAME#106,LOT_V6_OCCUPATION_GROUP#107,LOT_V6_OCCUPATION_GROUP_NAME#108,LOT_V6_CAREER_AREA#109,LOT_V6_CAREER_AREA_NAME#110,SOC_2#111,SOC_2_NAME#112,SOC_3#113,SOC_3_NAME#114,SOC_4#115,SOC_4_NAME#116,SOC_5#117,SOC_5_NAME#118,LIGHTCAST_SECTORS#119,LIGHTCAST_SECTORS_NAME#120,NAICS_2022_2#121,NAICS_2022_2_NAME#122,NAICS_2022_3#123,NAICS_2022_3_NAME#124,NAICS_2022_4#125,NAICS_2022_4_NAME#126,NAICS_2022_5#127,NAICS_2022_5_NAME#128,NAICS_2022_6#129,NAICS_2022_6_NAME#130] csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize JobMarketDataProcessor and Demonstrate Cleaning Pipeline\n",
    "if analyzer is not None:\n",
    "    print(\"STAGE 3: DATA CLEANING PIPELINE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize our data processor\n",
    "    print(\"Initializing JobMarketDataProcessor...\")\n",
    "    processor = JobMarketDataProcessor(\"PipelineDemo\")\n",
    "    \n",
    "    # Set the raw data\n",
    "    processor.df_raw = analyzer.job_data\n",
    "    print(f\"Processor initialized with {processor.df_raw.count():,} raw records\")\n",
    "    \n",
    "    # Demonstrate the cleaning pipeline step by step\n",
    "    print(\"\\nApplying Data Cleaning Pipeline...\")\n",
    "    \n",
    "    # Record initial state\n",
    "    initial_count = processor.df_raw.count()\n",
    "    initial_columns = set(processor.df_raw.columns)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Apply the cleaning and standardization\n",
    "        print(\"Calling clean_and_process_data_optimized()...\")\n",
    "        cleaned_df = processor.clean_and_process_data_optimized(processor.df_raw)\n",
    "        \n",
    "        cleaning_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Method completed. Returned DataFrame: {cleaned_df is not None}\")\n",
    "        \n",
    "        # Check if the processor has stored the processed data\n",
    "        if hasattr(processor, 'df_processed'):\n",
    "            print(f\"processor.df_processed exists: {processor.df_processed is not None}\")\n",
    "            if processor.df_processed is not None:\n",
    "                print(\"âœ“ Processor df_processed is set correctly\")\n",
    "            else:\n",
    "                print(\"! Setting processor.df_processed manually\")\n",
    "                processor.df_processed = cleaned_df\n",
    "        else:\n",
    "            print(\"! processor.df_processed attribute does not exist, creating it\")\n",
    "            processor.df_processed = cleaned_df\n",
    "        \n",
    "        # Verify the cleaned data\n",
    "        if cleaned_df is not None:\n",
    "            # Analyze the results\n",
    "            final_count = cleaned_df.count()\n",
    "            final_columns = set(cleaned_df.columns)\n",
    "            \n",
    "            # Calculate changes\n",
    "            record_change = final_count - initial_count\n",
    "            new_columns = final_columns - initial_columns\n",
    "            removed_columns = initial_columns - final_columns\n",
    "            \n",
    "            print(f\"\\nCleaning Pipeline Results:\")\n",
    "            print(f\"  Processing Time: {cleaning_time:.2f} seconds\")\n",
    "            print(f\"  Records Before: {initial_count:,}\")\n",
    "            print(f\"  Records After:  {final_count:,}\")\n",
    "            print(f\"  Record Change:  {record_change:+,}\")\n",
    "            \n",
    "            if record_change != 0:\n",
    "                pct_change = (record_change / initial_count) * 100\n",
    "                print(f\"  Percentage Change: {pct_change:+.2f}%\")\n",
    "            \n",
    "            print(f\"\\nColumn Changes:\")\n",
    "            print(f\"  Columns Before: {len(initial_columns)}\")\n",
    "            print(f\"  Columns After:  {len(final_columns)}\")\n",
    "            \n",
    "            if new_columns:\n",
    "                print(f\"  New Columns Created ({len(new_columns)}):\")\n",
    "                for col in sorted(list(new_columns)[:5]):  # Show first 5\n",
    "                    print(f\"    + {col}\")\n",
    "                if len(new_columns) > 5:\n",
    "                    print(f\"    ... and {len(new_columns) - 5} more\")\n",
    "            \n",
    "            if removed_columns:\n",
    "                print(f\"  Columns Removed ({len(removed_columns)}):\")\n",
    "                for col in sorted(list(removed_columns)[:3]):  # Show first 3\n",
    "                    print(f\"    - {col}\")\n",
    "                if len(removed_columns) > 3:\n",
    "                    print(f\"    ... and {len(removed_columns) - 3} more\")\n",
    "            \n",
    "            print(\"\\nData cleaning pipeline completed successfully!\")\n",
    "            print(\"âœ“ Processed data is ready for next stages\")\n",
    "        else:\n",
    "            print(\"ERROR: Cleaning method returned None\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error in cleaning pipeline: {e}\")\n",
    "        print(\"Full traceback:\")\n",
    "        traceback.print_exc()\n",
    "        cleaned_df = None\n",
    "        \n",
    "else:\n",
    "    print(\"Cannot proceed with cleaning - raw data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2463af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot show before/after comparison - cleaned data not available\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate Before/After Comparison of Key Data Quality Improvements\n",
    "if 'cleaned_df' in locals() and cleaned_df is not None:\n",
    "    print(\"\\nSTAGE 4: BEFORE/AFTER DATA QUALITY COMPARISON\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Compare company name standardization (null handling)\n",
    "    print(\"1. Company Name Standardization:\")\n",
    "    \n",
    "    # Before: Check null companies in raw data\n",
    "    raw_null_companies = processor.df_raw.filter(col(\"COMPANY\").isNull()).count()\n",
    "    \n",
    "    # After: Check null companies in cleaned data  \n",
    "    clean_null_companies = cleaned_df.filter(col(\"COMPANY\").isNull()).count()\n",
    "    \n",
    "    print(f\"   Raw Data - Null Companies: {raw_null_companies:,}\")\n",
    "    print(f\"   Cleaned Data - Null Companies: {clean_null_companies:,}\")\n",
    "    print(f\"   Improvement: {raw_null_companies - clean_null_companies:,} nulls handled\")\n",
    "    \n",
    "    # Show sample of company standardization\n",
    "    print(\"\\n   Sample Company Name Standardization:\")\n",
    "    if \"COMPANY\" in cleaned_df.columns:\n",
    "        company_sample = cleaned_df.select(\"COMPANY\").distinct().limit(5).collect()\n",
    "        for row in company_sample:\n",
    "            print(f\"   '{row.COMPANY}'\")\n",
    "    \n",
    "    # 2. Location data standardization\n",
    "    if \"LOCATION\" in cleaned_df.columns:\n",
    "        print(\"\\n2. Location Data Standardization:\")\n",
    "        location_sample = cleaned_df.select(\"LOCATION\").filter(col(\"LOCATION\").isNotNull()).limit(3).collect()\n",
    "        for row in location_sample:\n",
    "            print(f\"   '{row.LOCATION}'\")\n",
    "    \n",
    "    # 3. Salary data validation\n",
    "    if any(\"SALARY\" in col_name for col_name in cleaned_df.columns):\n",
    "        print(\"\\n3. Salary Data Quality:\")\n",
    "        salary_cols = [col_name for col_name in cleaned_df.columns if \"SALARY\" in col_name]\n",
    "        \n",
    "        for sal_col in salary_cols[:2]:  # Show first 2 salary columns\n",
    "            non_null_count = cleaned_df.filter(col(sal_col).isNotNull()).count()\n",
    "            coverage = (non_null_count / final_count) * 100 if final_count > 0 else 0\n",
    "            print(f\"   {sal_col}: {non_null_count:,} values ({coverage:.1f}% coverage)\")\n",
    "    \n",
    "    print(\"\\nData quality improvements applied successfully!\")\n",
    "    print(\"Ready for feature engineering stage.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot show before/after comparison - cleaned data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7d1ac",
   "metadata": {},
   "source": [
    "## Section 4: Feature Engineering Process\n",
    "\n",
    "Demonstrate the automated feature engineering capabilities that create derived columns and enhance the dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51fb5dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking processor and data state...\n",
      "ERROR: Cannot find necessary data\n",
      "cleaned_df is None: True\n",
      "processor is None: False\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering Analysis - Working Version\n",
    "print(\"DEBUG: Checking processor and data state...\")\n",
    "\n",
    "# Check available data sources and force assignment\n",
    "if cleaned_df is not None and processor is not None:\n",
    "    print(\"âœ“ Found cleaned_df and processor - setting up analysis...\")\n",
    "    processor.df_processed = cleaned_df\n",
    "    \n",
    "    print(\"STAGE 5: FEATURE ENGINEERING ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"Analyzing feature engineering results from cleaning pipeline...\")\n",
    "    print(\"(Feature engineering was automatically applied during data cleaning)\")\n",
    "    \n",
    "    enhanced_df = processor.df_processed\n",
    "    \n",
    "    # Analyze the feature engineering results that were applied during cleaning\n",
    "    all_columns = set(enhanced_df.columns)\n",
    "    \n",
    "    print(f\"\\nDataset Analysis:\")\n",
    "    print(f\"  Total Columns: {len(all_columns)}\")\n",
    "    print(f\"  Total Records: {enhanced_df.count():,}\")\n",
    "    \n",
    "    # Show a sample of column names to understand what was created\n",
    "    print(f\"\\nSample Column Names:\")\n",
    "    sample_cols = sorted(list(all_columns))[:15]\n",
    "    for i, col_name in enumerate(sample_cols):\n",
    "        marker = \"  â€¢\"\n",
    "        if \"_CLEAN\" in col_name:\n",
    "            marker = \"  âœ“\"\n",
    "        elif \"_IMPUTED\" in col_name:\n",
    "            marker = \"  +\"\n",
    "        elif \"_AVG\" in col_name:\n",
    "            marker = \"  $\"\n",
    "        print(f\"{marker} {col_name}\")\n",
    "    \n",
    "    if len(all_columns) > 15:\n",
    "        print(f\"  ... and {len(all_columns) - 15} more columns\")\n",
    "    \n",
    "    # Categorize features\n",
    "    feature_categories = {\n",
    "        'Original Fields': [f for f in all_columns if not any(suffix in f for suffix in ['_CLEAN', '_IMPUTED', '_AVG'])],\n",
    "        'Cleaned Fields': [f for f in all_columns if f.endswith('_CLEAN')],\n",
    "        'Imputed Fields': [f for f in all_columns if '_IMPUTED' in f],\n",
    "        'Calculated Fields': [f for f in all_columns if '_AVG' in f]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nFeature Category Summary:\")\n",
    "    for category, features in feature_categories.items():\n",
    "        print(f\"  {category}: {len(features)} columns\")\n",
    "    \n",
    "    # Show sample records for key columns\n",
    "    key_columns = [col_name for col_name in ['TITLE', 'COMPANY', 'SALARY_AVG_IMPUTED', 'COMPANY_CLEAN'] if col_name in all_columns]\n",
    "    if key_columns:\n",
    "        print(f\"\\nSample Data (first 2 records, key columns):\")\n",
    "        try:\n",
    "            sample_data = enhanced_df.select(key_columns).limit(2).collect()\n",
    "            for i, row in enumerate(sample_data, 1):\n",
    "                print(f\"  Record {i}:\")\n",
    "                for col_name in key_columns:\n",
    "                    value = getattr(row, col_name, 'N/A')\n",
    "                    if value is None:\n",
    "                        value = 'NULL'\n",
    "                    elif isinstance(value, str) and len(value) > 40:\n",
    "                        value = value[:37] + \"...\"\n",
    "                    elif isinstance(value, (int, float)):\n",
    "                        if 'SALARY' in col_name:\n",
    "                            value = f\"${value:,.0f}\"\n",
    "                    print(f\"    {col_name}: {value}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    (Sample data display failed: {e})\")\n",
    "    \n",
    "    print(f\"\\nFeature engineering analysis completed!\")\n",
    "    print(f\"Dataset is analysis-ready with {len(all_columns)} total columns.\")\n",
    "    print(f\"âœ“ Processor.df_processed is now properly set\")\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR: Cannot find necessary data\")\n",
    "    print(f\"cleaned_df is None: {cleaned_df is None}\")\n",
    "    print(f\"processor is None: {processor is None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4be01a",
   "metadata": {},
   "source": [
    "## Section 5: Data Quality Assessment\n",
    "\n",
    "Perform comprehensive quality checks on the fully processed dataset to ensure it meets our standards for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cadc032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot perform quality assessment - processed data not available\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Data Quality Assessment on Processed Dataset\n",
    "if hasattr(processor, 'df_processed') and processor.df_processed is not None:\n",
    "    print(\"STAGE 6: COMPREHENSIVE DATA QUALITY ASSESSMENT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    final_df = processor.df_processed\n",
    "    \n",
    "    # Create analyzer for the processed data\n",
    "    processed_analyzer = SparkJobAnalyzer()\n",
    "    processed_analyzer.job_data = final_df\n",
    "    processed_analyzer.job_data.createOrReplaceTempView(\"processed_jobs\")\n",
    "    \n",
    "    print(\"1. Dataset Overview:\")\n",
    "    print(f\"   Final Record Count: {final_df.count():,}\")\n",
    "    print(f\"   Final Column Count: {len(final_df.columns)}\")\n",
    "    \n",
    "    # Generate comprehensive statistics using our analyzer\n",
    "    try:\n",
    "        stats = processed_analyzer.get_overall_statistics()\n",
    "        \n",
    "        print(f\"\\n2. Key Statistics:\")\n",
    "        metrics_to_show = ['total_records', 'unique_companies', 'unique_locations', 'median_salary']\n",
    "        \n",
    "        for metric in metrics_to_show:\n",
    "            if metric in stats:\n",
    "                value = stats[metric]\n",
    "                if 'salary' in metric and isinstance(value, (int, float)):\n",
    "                    print(f\"   {metric.replace('_', ' ').title()}: ${value:,.0f}\")\n",
    "                else:\n",
    "                    print(f\"   {metric.replace('_', ' ').title()}: {value:,}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"   Could not generate statistics: {e}\")\n",
    "    \n",
    "    # 3. Data completeness analysis for critical columns\n",
    "    print(f\"\\n3. Data Completeness Analysis:\")\n",
    "    critical_analysis_columns = ['TITLE', 'COMPANY', 'SALARY_AVG_IMPUTED', 'EXPERIENCE_LEVEL_CLEAN']\n",
    "    existing_analysis_cols = [col for col in critical_analysis_columns if col in final_df.columns]\n",
    "    \n",
    "    total_records = final_df.count()\n",
    "    \n",
    "    for col in existing_analysis_cols:\n",
    "        non_null_count = final_df.filter(col(col).isNotNull()).count()\n",
    "        completeness = (non_null_count / total_records) * 100 if total_records > 0 else 0\n",
    "        print(f\"   {col}: {completeness:.1f}% complete ({non_null_count:,}/{total_records:,})\")\n",
    "    \n",
    "    # 4. Business rule validation\n",
    "    print(f\"\\n4. Business Rule Validation:\")\n",
    "    \n",
    "    # Check salary ranges\n",
    "    if 'SALARY_AVG_IMPUTED' in final_df.columns:\n",
    "        salary_stats = final_df.select(\n",
    "            spark_min('SALARY_AVG_IMPUTED').alias('min_salary'),\n",
    "            spark_max('SALARY_AVG_IMPUTED').alias('max_salary'),\n",
    "            avg('SALARY_AVG_IMPUTED').alias('avg_salary')\n",
    "        ).collect()[0]\n",
    "        \n",
    "        print(f\"   Salary Range: ${salary_stats.min_salary:,.0f} - ${salary_stats.max_salary:,.0f}\")\n",
    "        print(f\"   Average Salary: ${salary_stats.avg_salary:,.0f}\")\n",
    "        \n",
    "        # Validate reasonable salary ranges\n",
    "        reasonable_salaries = final_df.filter(\n",
    "            (col('SALARY_AVG_IMPUTED') >= 20000) & \n",
    "            (col('SALARY_AVG_IMPUTED') <= 500000)\n",
    "        ).count()\n",
    "        reasonable_pct = (reasonable_salaries / total_records) * 100 if total_records > 0 else 0\n",
    "        print(f\"   Reasonable Salaries: {reasonable_pct:.1f}% ({reasonable_salaries:,} records)\")\n",
    "    \n",
    "    # Check for duplicate records (if ID column exists)\n",
    "    id_columns = [col for col in final_df.columns if 'ID' in col.upper()]\n",
    "    if id_columns:\n",
    "        id_col = id_columns[0]\n",
    "        unique_ids = final_df.select(id_col).distinct().count()\n",
    "        duplicate_rate = ((total_records - unique_ids) / total_records) * 100 if total_records > 0 else 0\n",
    "        print(f\"   Duplicate Rate: {duplicate_rate:.2f}% (based on {id_col})\")\n",
    "    \n",
    "    print(f\"\\n5. Data Distribution Summary:\")\n",
    "    # Show top companies, locations, etc.\n",
    "    if 'COMPANY' in final_df.columns:\n",
    "        top_companies = final_df.groupBy('COMPANY').count().orderBy(col('count').desc()).limit(3).collect()\n",
    "        print(f\"   Top Companies:\")\n",
    "        for row in top_companies:\n",
    "            print(f\"     {row.COMPANY}: {row.count:,} jobs\")\n",
    "    \n",
    "    print(\"\\nData quality assessment completed!\")\n",
    "    print(\"Dataset has passed quality checks and is ready for analysis and export.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot perform quality assessment - processed data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec8683",
   "metadata": {},
   "source": [
    "## Section 6: Export and Persistence\n",
    "\n",
    "Now that we have processed, validated data, we'll demonstrate how to export it in multiple formats and validate our persistence operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf6d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot export data - processed data not available\n"
     ]
    }
   ],
   "source": [
    "# Export and Persistence Operations\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "if hasattr(processor, 'df_processed') and processor.df_processed is not None:\n",
    "    print(\"SECTION 6: EXPORT AND PERSISTENCE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    processed_data = processor.df_processed\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Define export paths\n",
    "    export_base_path = \"/home/samarthya/sourcebox/github.com/project-from-scratch/data/processed\"\n",
    "    parquet_path = f\"{export_base_path}/processed_jobs_{timestamp}.parquet\"\n",
    "    csv_path = f\"{export_base_path}/processed_jobs_{timestamp}.csv\"\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    os.makedirs(export_base_path, exist_ok=True)\n",
    "    \n",
    "    print(\"1. Multi-Format Export Operations:\")\n",
    "    \n",
    "    # Export to Parquet (efficient for analytics)\n",
    "    try:\n",
    "        print(\"   Exporting to Parquet format...\")\n",
    "        processed_data.coalesce(1).write.mode(\"overwrite\").parquet(parquet_path)\n",
    "        print(f\"   âœ“ Parquet export completed: {parquet_path}\")\n",
    "        \n",
    "        # Verify parquet file\n",
    "        parquet_verification = spark.read.parquet(parquet_path)\n",
    "        parquet_count = parquet_verification.count()\n",
    "        print(f\"   âœ“ Parquet verification: {parquet_count:,} records\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Parquet export failed: {e}\")\n",
    "    \n",
    "    # Export to CSV (for external tools)\n",
    "    try:\n",
    "        print(\"   Exporting to CSV format...\")\n",
    "        processed_data.coalesce(1).write.mode(\"overwrite\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"escape\", '\"') \\\n",
    "            .csv(csv_path)\n",
    "        print(f\"   âœ“ CSV export completed: {csv_path}\")\n",
    "        \n",
    "        # Verify CSV file\n",
    "        csv_verification = spark.read.option(\"header\", \"true\").csv(csv_path)\n",
    "        csv_count = csv_verification.count()\n",
    "        print(f\"   âœ“ CSV verification: {csv_count:,} records\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— CSV export failed: {e}\")\n",
    "    \n",
    "    print(f\"\\n2. Schema and Metadata Export:\")\n",
    "    \n",
    "    # Export schema information\n",
    "    try:\n",
    "        schema_info = {\n",
    "            'timestamp': timestamp,\n",
    "            'record_count': processed_data.count(),\n",
    "            'column_count': len(processed_data.columns),\n",
    "            'columns': [{'name': field.name, 'type': str(field.dataType)} for field in processed_data.schema.fields],\n",
    "            'export_paths': {\n",
    "                'parquet': parquet_path,\n",
    "                'csv': csv_path\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"   Schema captured: {len(schema_info['columns'])} columns\")\n",
    "        print(f\"   Record count: {schema_info['record_count']:,}\")\n",
    "        \n",
    "        # Show sample of column information\n",
    "        print(\"   Column Types (first 5):\")\n",
    "        for col_info in schema_info['columns'][:5]:\n",
    "            print(f\"     {col_info['name']}: {col_info['type']}\")\n",
    "        \n",
    "        # Save schema as JSON\n",
    "        import json\n",
    "        schema_path = f\"{export_base_path}/schema_{timestamp}.json\"\n",
    "        with open(schema_path, 'w') as f:\n",
    "            json.dump(schema_info, f, indent=2)\n",
    "        print(f\"   âœ“ Schema metadata saved: {schema_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Schema export failed: {e}\")\n",
    "    \n",
    "    print(f\"\\n3. Data Loading Validation:\")\n",
    "    \n",
    "    # Test loading from each export format\n",
    "    try:\n",
    "        # Test Parquet loading\n",
    "        reloaded_parquet = spark.read.parquet(parquet_path)\n",
    "        parquet_reload_count = reloaded_parquet.count()\n",
    "        parquet_reload_cols = len(reloaded_parquet.columns)\n",
    "        \n",
    "        print(f\"   Parquet Reload Test:\")\n",
    "        print(f\"     Records: {parquet_reload_count:,}\")\n",
    "        print(f\"     Columns: {parquet_reload_cols}\")\n",
    "        \n",
    "        # Test CSV loading\n",
    "        reloaded_csv = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(csv_path)\n",
    "        csv_reload_count = reloaded_csv.count()\n",
    "        csv_reload_cols = len(reloaded_csv.columns)\n",
    "        \n",
    "        print(f\"   CSV Reload Test:\")\n",
    "        print(f\"     Records: {csv_reload_count:,}\")\n",
    "        print(f\"     Columns: {csv_reload_cols}\")\n",
    "        \n",
    "        # Verify data integrity\n",
    "        original_count = processed_data.count()\n",
    "        data_integrity_check = (parquet_reload_count == original_count and csv_reload_count == original_count)\n",
    "        \n",
    "        print(f\"\\n   Data Integrity Check: {'âœ“ PASSED' if data_integrity_check else 'âœ— FAILED'}\")\n",
    "        print(f\"   Original: {original_count:,} | Parquet: {parquet_reload_count:,} | CSV: {csv_reload_count:,}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Data loading validation failed: {e}\")\n",
    "    \n",
    "    print(f\"\\n4. Export Summary:\")\n",
    "    try:\n",
    "        # Get file sizes\n",
    "        import glob\n",
    "        \n",
    "        parquet_files = glob.glob(f\"{parquet_path}/*.parquet\")\n",
    "        csv_files = glob.glob(f\"{csv_path}/*.csv\")\n",
    "        \n",
    "        if parquet_files:\n",
    "            parquet_size = sum(os.path.getsize(f) for f in parquet_files)\n",
    "            print(f\"   Parquet Size: {parquet_size / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        if csv_files:\n",
    "            csv_size = sum(os.path.getsize(f) for f in csv_files)\n",
    "            print(f\"   CSV Size: {csv_size / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        print(f\"   Export completed successfully!\")\n",
    "        print(f\"   Files available in: {export_base_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Could not determine file sizes: {e}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot export data - processed data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaee1e22",
   "metadata": {},
   "source": [
    "## Section 7: Pipeline Performance Metrics\n",
    "\n",
    "Let's analyze the performance characteristics of our data processing pipeline and measure the efficiency of each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e0fc2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SECTION 7: PIPELINE PERFORMANCE METRICS\n",
      "=======================================================\n",
      "1. Memory Usage Analysis:\n",
      "   Current Memory Usage: 204.41 MB\n",
      "   Could not analyze memory usage: name 'spark' is not defined\n",
      "\n",
      "2. Data Processing Stages Summary:\n",
      "\n",
      "3. Feature Engineering Impact:\n",
      "\n",
      "4. Processing Time Estimation:\n",
      "\n",
      "5. Resource Utilization Summary:\n",
      "   CPU Usage: 4.8%\n",
      "   Workspace Disk Usage: 7.7%\n",
      "   Available Disk Space: 877.7 GB\n",
      "\n",
      "6. Pipeline Efficiency Assessment:\n",
      "\n",
      "Performance analysis completed!\n",
      "Pipeline metrics captured at: 2025-09-29 21:38:16\n",
      "   CPU Usage: 4.8%\n",
      "   Workspace Disk Usage: 7.7%\n",
      "   Available Disk Space: 877.7 GB\n",
      "\n",
      "6. Pipeline Efficiency Assessment:\n",
      "\n",
      "Performance analysis completed!\n",
      "Pipeline metrics captured at: 2025-09-29 21:38:16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline Performance Analysis\n",
    "import time\n",
    "import psutil\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"SECTION 7: PIPELINE PERFORMANCE METRICS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Performance metrics collection\n",
    "performance_metrics = {}\n",
    "\n",
    "print(\"1. Memory Usage Analysis:\")\n",
    "try:\n",
    "    # Get current memory usage\n",
    "    process = psutil.Process()\n",
    "    memory_info = process.memory_info()\n",
    "    memory_mb = memory_info.rss / (1024 * 1024)\n",
    "    \n",
    "    print(f\"   Current Memory Usage: {memory_mb:.2f} MB\")\n",
    "    \n",
    "    # Get Spark context memory info if available\n",
    "    if spark:\n",
    "        spark_conf = spark.sparkContext.getConf()\n",
    "        driver_memory = spark_conf.get('spark.driver.memory', 'Not configured')\n",
    "        executor_memory = spark_conf.get('spark.executor.memory', 'Not configured')\n",
    "        \n",
    "        print(f\"   Spark Driver Memory: {driver_memory}\")\n",
    "        print(f\"   Spark Executor Memory: {executor_memory}\")\n",
    "        \n",
    "        # Check active Spark jobs\n",
    "        spark_context = spark.sparkContext\n",
    "        print(f\"   Active Spark Jobs: {len(spark_context.statusTracker().getActiveJobIds())}\")\n",
    "        \n",
    "    performance_metrics['memory_usage_mb'] = memory_mb\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   Could not analyze memory usage: {e}\")\n",
    "\n",
    "print(f\"\\n2. Data Processing Stages Summary:\")\n",
    "\n",
    "# Calculate processing efficiency if we have stage information\n",
    "if hasattr(processor, 'df_processed') and processor.df_processed is not None:\n",
    "    try:\n",
    "        original_count = raw_analyzer.job_data.count() if hasattr(raw_analyzer, 'job_data') else 0\n",
    "        processed_count = processor.df_processed.count()\n",
    "        \n",
    "        data_retention_rate = (processed_count / original_count * 100) if original_count > 0 else 0\n",
    "        records_filtered = original_count - processed_count\n",
    "        \n",
    "        print(f\"   Original Records: {original_count:,}\")\n",
    "        print(f\"   Processed Records: {processed_count:,}\")\n",
    "        print(f\"   Records Filtered: {records_filtered:,}\")\n",
    "        print(f\"   Data Retention Rate: {data_retention_rate:.1f}%\")\n",
    "        \n",
    "        performance_metrics.update({\n",
    "            'original_records': original_count,\n",
    "            'processed_records': processed_count,\n",
    "            'data_retention_rate': data_retention_rate\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Could not calculate processing metrics: {e}\")\n",
    "\n",
    "print(f\"\\n3. Feature Engineering Impact:\")\n",
    "\n",
    "# Analyze column creation and transformations\n",
    "if hasattr(processor, 'df_processed') and processor.df_processed is not None:\n",
    "    try:\n",
    "        original_columns = len(raw_analyzer.job_data.columns) if hasattr(raw_analyzer, 'job_data') else 0\n",
    "        processed_columns = len(processor.df_processed.columns)\n",
    "        columns_added = processed_columns - original_columns\n",
    "        \n",
    "        print(f\"   Original Columns: {original_columns}\")\n",
    "        print(f\"   Final Columns: {processed_columns}\")\n",
    "        print(f\"   Columns Added: {columns_added}\")\n",
    "        print(f\"   Feature Enhancement: {(columns_added/original_columns*100):.1f}% increase\" if original_columns > 0 else \"\")\n",
    "        \n",
    "        performance_metrics.update({\n",
    "            'original_columns': original_columns,\n",
    "            'final_columns': processed_columns,\n",
    "            'columns_added': columns_added\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Could not analyze feature engineering: {e}\")\n",
    "\n",
    "print(f\"\\n4. Processing Time Estimation:\")\n",
    "\n",
    "# Simulate a small processing operation to estimate timing\n",
    "try:\n",
    "    if hasattr(processor, 'df_processed') and processor.df_processed is not None:\n",
    "        print(\"   Running performance benchmark on sample data...\")\n",
    "        \n",
    "        # Time a simple aggregation operation\n",
    "        start_time = time.time()\n",
    "        sample_agg = processor.df_processed.groupBy('COMPANY').count().collect()\n",
    "        end_time = time.time()\n",
    "        \n",
    "        operation_time = end_time - start_time\n",
    "        records_per_second = processed_count / operation_time if operation_time > 0 else 0\n",
    "        \n",
    "        print(f\"   Sample Aggregation Time: {operation_time:.3f} seconds\")\n",
    "        print(f\"   Processing Rate: {records_per_second:,.0f} records/second\")\n",
    "        print(f\"   Unique Companies Found: {len(sample_agg):,}\")\n",
    "        \n",
    "        performance_metrics.update({\n",
    "            'sample_operation_time': operation_time,\n",
    "            'processing_rate_rps': records_per_second\n",
    "        })\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   Could not run performance benchmark: {e}\")\n",
    "\n",
    "print(f\"\\n5. Resource Utilization Summary:\")\n",
    "\n",
    "try:\n",
    "    # CPU usage\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    \n",
    "    # Disk usage for workspace\n",
    "    workspace_path = \"/home/samarthya/sourcebox/github.com/project-from-scratch\"\n",
    "    disk_usage = psutil.disk_usage(workspace_path)\n",
    "    \n",
    "    print(f\"   CPU Usage: {cpu_percent:.1f}%\")\n",
    "    print(f\"   Workspace Disk Usage: {(disk_usage.used / disk_usage.total * 100):.1f}%\")\n",
    "    print(f\"   Available Disk Space: {(disk_usage.free / (1024**3)):.1f} GB\")\n",
    "    \n",
    "    performance_metrics.update({\n",
    "        'cpu_percent': cpu_percent,\n",
    "        'disk_usage_percent': disk_usage.used / disk_usage.total * 100\n",
    "    })\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   Could not analyze resource utilization: {e}\")\n",
    "\n",
    "print(f\"\\n6. Pipeline Efficiency Assessment:\")\n",
    "\n",
    "try:\n",
    "    # Calculate overall efficiency score based on available metrics\n",
    "    efficiency_factors = []\n",
    "    \n",
    "    if 'data_retention_rate' in performance_metrics:\n",
    "        # Higher retention rate is generally better (less data loss)\n",
    "        retention_score = min(performance_metrics['data_retention_rate'] / 90.0, 1.0)  # 90% as target\n",
    "        efficiency_factors.append(('Data Retention', retention_score, f\"{performance_metrics['data_retention_rate']:.1f}%\"))\n",
    "    \n",
    "    if 'processing_rate_rps' in performance_metrics:\n",
    "        # Normalize processing rate (assume 1000 rps as good target)\n",
    "        rate_score = min(performance_metrics['processing_rate_rps'] / 1000.0, 1.0)\n",
    "        efficiency_factors.append(('Processing Speed', rate_score, f\"{performance_metrics['processing_rate_rps']:,.0f} rps\"))\n",
    "    \n",
    "    if 'memory_usage_mb' in performance_metrics:\n",
    "        # Lower memory usage is better (assume 2GB as reasonable limit)\n",
    "        memory_score = max(0, 1.0 - (performance_metrics['memory_usage_mb'] / 2048.0))\n",
    "        efficiency_factors.append(('Memory Efficiency', memory_score, f\"{performance_metrics['memory_usage_mb']:.0f} MB\"))\n",
    "    \n",
    "    if efficiency_factors:\n",
    "        overall_score = sum(score for _, score, _ in efficiency_factors) / len(efficiency_factors)\n",
    "        \n",
    "        print(f\"   Efficiency Components:\")\n",
    "        for factor_name, score, display_value in efficiency_factors:\n",
    "            score_pct = score * 100\n",
    "            print(f\"     {factor_name}: {score_pct:.1f}% ({display_value})\")\n",
    "        \n",
    "        print(f\"\\n   Overall Pipeline Efficiency: {overall_score*100:.1f}%\")\n",
    "        \n",
    "        # Performance recommendations\n",
    "        if overall_score > 0.8:\n",
    "            print(\"   Status: EXCELLENT - Pipeline is performing very well\")\n",
    "        elif overall_score > 0.6:\n",
    "            print(\"   Status: GOOD - Pipeline performance is acceptable\")\n",
    "        elif overall_score > 0.4:\n",
    "            print(\"   Status: MODERATE - Consider optimization opportunities\")\n",
    "        else:\n",
    "            print(\"   Status: NEEDS IMPROVEMENT - Performance optimization recommended\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   Could not calculate efficiency assessment: {e}\")\n",
    "\n",
    "print(f\"\\nPerformance analysis completed!\")\n",
    "print(f\"Pipeline metrics captured at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Force garbage collection to clean up memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca5f45",
   "metadata": {},
   "source": [
    "## Section 8: Interactive Data Exploration\n",
    "\n",
    "Finally, let's demonstrate how to convert our processed Spark DataFrame to Pandas for interactive analysis and create sample visualizations using our SalaryVisualizer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "708e0a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SECTION 8: INTERACTIVE DATA EXPLORATION\n",
      "=======================================================\n",
      "Cannot perform interactive exploration - processed data not available\n"
     ]
    }
   ],
   "source": [
    "# Interactive Data Exploration and Visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"SECTION 8: INTERACTIVE DATA EXPLORATION\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "if hasattr(processor, 'df_processed') and processor.df_processed is not None:\n",
    "    print(\"1. Spark to Pandas Conversion:\")\n",
    "    \n",
    "    try:\n",
    "        # Convert a sample to Pandas for interactive analysis\n",
    "        sample_size = min(5000, processor.df_processed.count())  # Limit to 5k records for demo\n",
    "        \n",
    "        print(f\"   Converting {sample_size:,} records to Pandas DataFrame...\")\n",
    "        pandas_df = processor.df_processed.limit(sample_size).toPandas()\n",
    "        \n",
    "        print(f\"   âœ“ Conversion successful!\")\n",
    "        print(f\"   Pandas DataFrame Shape: {pandas_df.shape}\")\n",
    "        print(f\"   Memory Usage: {pandas_df.memory_usage(deep=True).sum() / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        # Display basic info about the Pandas DataFrame\n",
    "        print(f\"\\n2. Pandas DataFrame Overview:\")\n",
    "        print(f\"   Data Types:\")\n",
    "        \n",
    "        # Show column types summary\n",
    "        type_counts = pandas_df.dtypes.value_counts()\n",
    "        for dtype, count in type_counts.items():\n",
    "            print(f\"     {dtype}: {count} columns\")\n",
    "        \n",
    "        # Show sample data\n",
    "        print(f\"\\n   Sample Records (first 3 rows):\")\n",
    "        display_columns = ['TITLE', 'COMPANY', 'SALARY_AVG_IMPUTED', 'EXPERIENCE_LEVEL_CLEAN']\n",
    "        available_display_cols = [col for col in display_columns if col in pandas_df.columns]\n",
    "        \n",
    "        if available_display_cols:\n",
    "            sample_data = pandas_df[available_display_cols].head(3)\n",
    "            for idx, row in sample_data.iterrows():\n",
    "                print(f\"     Row {idx + 1}:\")\n",
    "                for col in available_display_cols:\n",
    "                    value = row[col]\n",
    "                    if pd.isna(value):\n",
    "                        display_val = \"NULL\"\n",
    "                    elif 'SALARY' in col and isinstance(value, (int, float)):\n",
    "                        display_val = f\"${value:,.0f}\"\n",
    "                    else:\n",
    "                        display_val = str(value)[:50] + (\"...\" if len(str(value)) > 50 else \"\")\n",
    "                    print(f\"       {col}: {display_val}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Pandas conversion failed: {e}\")\n",
    "        pandas_df = None\n",
    "    \n",
    "    print(f\"\\n3. Quick Statistical Analysis:\")\n",
    "    \n",
    "    if pandas_df is not None:\n",
    "        try:\n",
    "            # Basic statistics for numerical columns\n",
    "            numeric_columns = pandas_df.select_dtypes(include=['number']).columns\n",
    "            \n",
    "            if len(numeric_columns) > 0:\n",
    "                print(f\"   Numerical Columns Analysis:\")\n",
    "                \n",
    "                for col in numeric_columns[:3]:  # Show first 3 numeric columns\n",
    "                    if pandas_df[col].notna().sum() > 0:\n",
    "                        stats = pandas_df[col].describe()\n",
    "                        print(f\"     {col}:\")\n",
    "                        print(f\"       Mean: {stats['mean']:,.2f}\")\n",
    "                        print(f\"       Median: {stats['50%']:,.2f}\")\n",
    "                        print(f\"       Range: {stats['min']:,.0f} - {stats['max']:,.0f}\")\n",
    "            \n",
    "            # Top categories for text columns\n",
    "            text_columns = pandas_df.select_dtypes(include=['object']).columns\n",
    "            print(f\"\\n   Categorical Analysis (top 3 categories):\")\n",
    "            \n",
    "            for col in text_columns[:2]:  # Show first 2 text columns\n",
    "                if col in pandas_df.columns:\n",
    "                    top_values = pandas_df[col].value_counts().head(3)\n",
    "                    print(f\"     {col}:\")\n",
    "                    for value, count in top_values.items():\n",
    "                        print(f\"       {value}: {count:,} ({count/len(pandas_df)*100:.1f}%)\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   Could not perform statistical analysis: {e}\")\n",
    "    \n",
    "    print(f\"\\n4. Sample Visualization Creation:\")\n",
    "    \n",
    "    # Try to create a simple visualization using our SalaryVisualizer\n",
    "    try:\n",
    "        # Initialize SalaryVisualizer with our processed data\n",
    "        visualizer = SalaryVisualizer()\n",
    "        \n",
    "        # Set up basic configuration\n",
    "        visualizer.df = processor.df_processed\n",
    "        \n",
    "        print(\"   Initializing SalaryVisualizer...\")\n",
    "        print(f\"   âœ“ Visualizer ready with {processor.df_processed.count():,} records\")\n",
    "        \n",
    "        # Create a simple chart (experience vs salary if columns exist)\n",
    "        salary_col = 'SALARY_AVG_IMPUTED' if 'SALARY_AVG_IMPUTED' in processor.df_processed.columns else None\n",
    "        experience_col = 'EXPERIENCE_LEVEL_CLEAN' if 'EXPERIENCE_LEVEL_CLEAN' in processor.df_processed.columns else None\n",
    "        \n",
    "        if salary_col and experience_col and pandas_df is not None:\n",
    "            print(f\"   Creating sample visualization: {experience_col} vs {salary_col}\")\n",
    "            \n",
    "            # Create a simple matplotlib visualization\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            # Group data for visualization\n",
    "            grouped_data = pandas_df.groupby(experience_col)[salary_col].agg(['mean', 'median', 'count']).reset_index()\n",
    "            \n",
    "            # Create bar plot\n",
    "            plt.bar(grouped_data[experience_col], grouped_data['mean'], alpha=0.7, color='skyblue', label='Mean Salary')\n",
    "            plt.bar(grouped_data[experience_col], grouped_data['median'], alpha=0.7, color='orange', width=0.5, label='Median Salary')\n",
    "            \n",
    "            plt.title('Salary Distribution by Experience Level\\n(Pipeline Demo Output)', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel('Experience Level', fontsize=12)\n",
    "            plt.ylabel('Salary ($)', fontsize=12)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Format y-axis as currency\n",
    "            plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the plot\n",
    "            chart_path = f\"/home/samarthya/sourcebox/github.com/project-from-scratch/figures/pipeline_demo_chart_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "            plt.savefig(chart_path, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"   âœ“ Chart created and saved: {chart_path}\")\n",
    "            \n",
    "            # Display summary statistics\n",
    "            print(f\"   Chart Summary:\")\n",
    "            for _, row in grouped_data.iterrows():\n",
    "                exp_level = row[experience_col]\n",
    "                mean_sal = row['mean']\n",
    "                count = row['count']\n",
    "                print(f\"     {exp_level}: ${mean_sal:,.0f} avg ({count:,} jobs)\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"   Required columns not available for visualization\")\n",
    "            print(f\"   Available columns: {list(processor.df_processed.columns)[:5]}...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Visualization creation failed: {e}\")\n",
    "    \n",
    "    print(f\"\\n5. Data Export for External Tools:\")\n",
    "    \n",
    "    if pandas_df is not None:\n",
    "        try:\n",
    "            # Export sample to Excel for business users\n",
    "            excel_path = f\"/home/samarthya/sourcebox/github.com/project-from-scratch/data/processed/pipeline_demo_sample_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "            pandas_df.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "            print(f\"   âœ“ Excel export: {excel_path}\")\n",
    "            \n",
    "            # Create summary report\n",
    "            summary_stats = {\n",
    "                'total_records': len(pandas_df),\n",
    "                'unique_companies': pandas_df['COMPANY'].nunique() if 'COMPANY' in pandas_df.columns else 'N/A',\n",
    "                'avg_salary': pandas_df['SALARY_AVG_IMPUTED'].mean() if 'SALARY_AVG_IMPUTED' in pandas_df.columns else 'N/A',\n",
    "                'date_generated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "            \n",
    "            print(f\"   Summary Report:\")\n",
    "            for key, value in summary_stats.items():\n",
    "                if isinstance(value, float):\n",
    "                    print(f\"     {key.replace('_', ' ').title()}: {value:,.2f}\")\n",
    "                else:\n",
    "                    print(f\"     {key.replace('_', ' ').title()}: {value}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Export to Excel failed: {e}\")\n",
    "    \n",
    "    print(f\"\\n6. Pipeline Demo Completion Summary:\")\n",
    "    print(\"   âœ“ Raw data successfully loaded using SparkJobAnalyzer\")\n",
    "    print(\"   âœ“ Data cleaning and feature engineering completed with JobMarketDataProcessor\")\n",
    "    print(\"   âœ“ Data quality assessment passed\")\n",
    "    print(\"   âœ“ Multi-format export operations successful\")\n",
    "    print(\"   âœ“ Performance metrics captured\")\n",
    "    print(\"   âœ“ Interactive analysis with Pandas conversion\")\n",
    "    print(\"   âœ“ Sample visualization created\")\n",
    "    print(\"   âœ“ Data ready for production analytics workflows\")\n",
    "    \n",
    "    print(f\"\\nDemonstration completed successfully!\")\n",
    "    print(f\"Your data processing pipeline is now fully operational and validated.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot perform interactive exploration - processed data not available\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
