---
title: "Predictive Analytics"
subtitle: "Machine Learning Insights for Job Market Analysis"
format:
  html:
    theme: cosmo
    toc: True
    code-fold: True
    code-tools: True
    embed-resources: True
    css: styles.css
    self-contained: true
execute:
  echo: False
  warning: False
  message: False
  cache: true
python:
  type: venv
  environment: .venv
---

## Overview

This page demonstrates basic predictive analytics using the job market data. We focus on simple, interpretable models that provide actionable insights for job seekers.

```{python}
#| label: data-loading
#| output: false

# Load processed data using centralized pipeline
from src.data import load_analysis_data
from src.config.column_mapping import get_analysis_column
from src.visualization.charts import display_figure
import pandas as pd
import numpy as np

df = load_analysis_data("predictive")

# Get standardized column names
salary_col = get_analysis_column('salary')
city_col = get_analysis_column('city')
```

```{python}
#| label: data-summary
#| output: asis

from IPython.display import Markdown, display

summary_text = f"""
**Data Loaded:**

- **Records**: {len(df):,}
- **Salary Column**: `{salary_col}`
- **Location Column**: `{city_col}`
"""

display(Markdown(summary_text))
```

## Salary Distribution Analysis

Understanding the overall salary landscape helps set realistic expectations.

```{python}
#| label: salary-distribution

# Use abstraction layer for salary distribution
from src.visualization import SalaryVisualizer

visualizer = SalaryVisualizer(df)
fig = visualizer.create_salary_distribution_histogram()

# Display figure with error handling
try:
    display_figure(fig, "salary_distribution_histogram")
except Exception as e:
    print(f"Chart display error: {e}")
    # Fallback: show basic info
    print(f"Median salary: ${df[salary_col].median():,.0f}")
    print(f"Salary range: ${df[salary_col].min():,.0f} - ${df[salary_col].max():,.0f}")
```

```{python}
#| label: salary-statistics
#| output: asis

from IPython.display import Markdown, display

# Calculate salary statistics
median_salary = df[salary_col].median()
mean_salary = df[salary_col].mean()
q25_salary = df[salary_col].quantile(0.25)
q75_salary = df[salary_col].quantile(0.75)

stats_text = f"""
**Salary Statistics:**

- **Median**: ${median_salary:,.0f}
- **Mean**: ${mean_salary:,.0f}
- **25th Percentile**: ${q25_salary:,.0f}
- **75th Percentile**: ${q75_salary:,.0f}
"""

display(Markdown(stats_text))
```

## Geographic Salary Analysis

Where you work significantly impacts compensation.

```{python}
#| label: geographic-analysis

# Use abstraction layer for geographic analysis
from src.visualization import SalaryVisualizer

visualizer = SalaryVisualizer(df)
fig = visualizer.create_geographic_salary_bar_chart()

display_figure(fig, "geographic_salary_comparison")
```

## Simple Salary Prediction

We can predict salary ranges based on key factors using simple machine learning.

```{python}
#| label: simple-prediction

# Use PySpark MLlib for salary prediction
import numpy as np
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.ml.regression import LinearRegression
from pyspark.ml.feature import VectorAssembler, StringIndexer
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import RegressionEvaluator

# Initialize Spark session
from src.utils.spark_utils import create_spark_session
spark = create_spark_session("PredictiveAnalytics")

# Filter out rows with null salaries
valid_salary_mask = df[salary_col].notna()
df_model = df[valid_salary_mask].copy()

print(f"Training data: {len(df_model):,} records with salary information")

# Convert to Spark DataFrame
spark_df = spark.createDataFrame(df_model)

# Prepare features using PySpark
feature_cols = []
stages = []

# Experience (if available)
if 'min_years_experience' in df_model.columns:
    spark_df = spark_df.withColumn('experience_clean',
                                   F.when(F.col('min_years_experience').isNull(), 0)
                                   .otherwise(F.col('min_years_experience')))
    feature_cols.append('experience_clean')

# City (top 10 only to avoid too many categories)
if city_col in df_model.columns:
    # Get top 10 cities
    top_cities = df_model[city_col].value_counts().head(10).index.tolist()
    spark_df = spark_df.withColumn('city_top10',
                                   F.when(F.col(city_col).isin(top_cities), F.col(city_col))
                                   .otherwise(F.lit('Other')))
    # String indexer for city
    city_indexer = StringIndexer(inputCol='city_top10', outputCol='city_indexed', handleInvalid='keep')
    stages.append(city_indexer)
    feature_cols.append('city_indexed')

# Industry (if available)
industry_col = 'industry' if 'industry' in df_model.columns else 'naics2_name'
if industry_col in df_model.columns:
    spark_df = spark_df.withColumn('industry_clean',
                                   F.when(F.col(industry_col).isNull(), 'Unknown')
                                   .otherwise(F.col(industry_col)))
    # String indexer for industry
    industry_indexer = StringIndexer(inputCol='industry_clean', outputCol='industry_indexed', handleInvalid='keep')
    stages.append(industry_indexer)
    feature_cols.append('industry_indexed')

print(f"Features to use: {feature_cols}")

if len(feature_cols) > 0:
    # Assemble features into vector
    assembler = VectorAssembler(inputCols=feature_cols, outputCol='features', handleInvalid='skip')
    stages.append(assembler)

    # Linear regression model
    lr = LinearRegression(featuresCol='features', labelCol=salary_col,
                          maxIter=10, regParam=0.01, elasticNetParam=0.0)
    stages.append(lr)

    # Create pipeline
    pipeline = Pipeline(stages=stages)

    # Train model
    model = pipeline.fit(spark_df)

    # Make predictions
    predictions = model.transform(spark_df)

    # Calculate metrics using PySpark evaluator
    evaluator_r2 = RegressionEvaluator(labelCol=salary_col, predictionCol='prediction', metricName='r2')
    evaluator_rmse = RegressionEvaluator(labelCol=salary_col, predictionCol='prediction', metricName='rmse')

    r2 = evaluator_r2.evaluate(predictions)
    rmse = evaluator_rmse.evaluate(predictions)

    print(f"\nModel Performance (PySpark MLlib):")
    print(f"- R²: {r2:.3f}")
    print(f"- RMSE: ${rmse:,.0f}")
    print(f"- Features used: {feature_cols}")

    # Get the trained Linear Regression model from the pipeline
    lr_model = model.stages[-1]
    if hasattr(lr_model, 'coefficients'):
        print(f"\nFeature Coefficients:")
        for i, feature in enumerate(feature_cols):
            if i < len(lr_model.coefficients):
                print(f"- {feature}: {lr_model.coefficients[i]:.2f}")

    # Set features variable for downstream use
    features = feature_cols
else:
    print("❌ No suitable features found for prediction")
    r2 = 0
    rmse = 0
    features = []
```

```{python}
#| label: model-results
#| output: asis

from IPython.display import Markdown, display

# Simple results display
results_text = f"""
### Machine Learning Results:

**Model Performance:**

- **R² Score**: {r2:.3f} (explains {r2*100:.1f}% of salary variance)
- **Root Mean Square Error**: ${rmse:,.0f}
- **Training Samples**: {len(df_model):,}

**Features Used** ({len(features)} features):

{chr(10).join(f"- `{feat}`" for feat in features)}

*These features were identified as the strongest predictors of salary based on the data analysis.*
"""

display(Markdown(results_text))
```

## Key Insights for Job Seekers

Based on the predictive models and analysis above, here are data-driven recommendations:

### Location Strategy

*Insights from the [Geographic Salary Analysis](#geographic-salary-analysis) chart:*

- **Target high-paying markets** identified in the geographic analysis above
- Consider **cost of living** alongside salary when evaluating offers
- **Remote opportunities** may offer flexibility while maintaining competitive salaries
- Use the salary prediction model to estimate your earning potential in different cities

### Career Planning

*Insights from the [Machine Learning Model](#simple-salary-prediction) results:*

- **Experience matters**: Our model shows salary progression across career stages
- **Specialization pays**: Certain skills and titles command premium compensation
- **Market awareness**: Understanding salary ranges strengthens negotiations
- The ML model explains **{r2*100:.1f}% of salary variance**, showing predictable patterns

### How to Use This Analysis

1. **Benchmark your offers** against the median salary (${median_salary:,.0f}) and predicted ranges
2. **Identify high-opportunity markets** using the geographic salary chart above
3. **Plan skill development** in areas that correlate with higher salaries
4. **Estimate your market value** using the factors identified by the ML model

---

```{python}
#| label: footer-text
#| output: asis

from IPython.display import Markdown, display
display(Markdown(f"*Analysis based on {len(df):,} real job postings. Data is continuously updated to reflect current market conditions.*"))
```
